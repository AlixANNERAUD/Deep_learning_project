{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b91849",
   "metadata": {},
   "source": [
    "# PUMA Challenge - Training HoVer-Net\n",
    "\n",
    "This notebook demonstrates how to train the HoVer-Net model for the Panoptic Segmentation of nUclei and tissue in advanced MelanomA (PUMA) challenge. \n",
    "\n",
    "## PUMA Challenge Overview\n",
    "\n",
    "The PUMA challenge consists of two tracks, each with two tasks:\n",
    "\n",
    "### Track 1 – Panoptic segmentation with three instance classes:\n",
    "- **Task 1**: Semantic tissue segmentation of tumor, stroma, epithelium, blood vessel, and necrotic regions.\n",
    "- **Task 2**: Nuclei detection for three classes; tumor, TILs (lymphocytes and plasma cells), and other cells.\n",
    "\n",
    "### Track 2 – Panoptic segmentation with ten instance classes:\n",
    "- **Task 1**: Semantic tissue segmentation (same as Track 1).\n",
    "- **Task 2**: Nuclei detection for all ten classes: tumor, lymphocytes, plasma cells, histiocytes, melanophages, neutrophils, stromal cells, epithelium, endothelium, and apoptotic cells.\n",
    "\n",
    "In this notebook, we'll focus on training HoVer-Net for both tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01efdc",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment and import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "769f4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Add HoVer-Net directory to path\n",
    "sys.path.append('./hover_net/')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8b8d6",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Understanding\n",
    "\n",
    "The PUMA dataset consists of:\n",
    "- 155 primary and 155 metastatic melanoma regions of interest (ROI), scanned at 40x magnification (1024 x 1024 pixels)\n",
    "- Context ROI of 5120 x 5120 pixels, centered around each ROI\n",
    "- Annotations for tissue and nuclei\n",
    "\n",
    "Let's explore the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "912bd4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "dataset_path = \"../dataset\"\n",
    "\n",
    "# List available ROIs\n",
    "nuclei_annotations_path = os.path.join(dataset_path, \"01_training_dataset_geojson_nuclei\")\n",
    "tissue_annotations_path = os.path.join(dataset_path, \"01_training_dataset_geojson_tissue\")\n",
    "roi_images_path = os.path.join(dataset_path, \"01_training_dataset_tif_ROIs\")\n",
    "context_roi_path = os.path.join(dataset_path, \"01_training_dataset_tif_context_ROIs\")\n",
    "\n",
    "# Count the number of files in each directory\n",
    "print(f\"Number of nuclei annotation files: {len(os.listdir(nuclei_annotations_path))}\")\n",
    "print(f\"Number of tissue annotation files: {len(os.listdir(tissue_annotations_path))}\")\n",
    "print(f\"Number of ROI image files: {len(os.listdir(roi_images_path))}\")\n",
    "print(f\"Number of context ROI image files: {len(os.listdir(context_roi_path))}\")\n",
    "\n",
    "# Look at sample filenames\n",
    "print(\"\\nSample nuclei annotation files:\")\n",
    "for file in os.listdir(nuclei_annotations_path)[:5]:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2195285",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "HoVer-Net requires the data in a specific format. For training, we need to:\n",
    "1. Convert GeoJSON annotations to instance masks\n",
    "2. Extract patches from original images\n",
    "3. Format data as required by HoVer-Net: [RGB, inst, type] channels\n",
    "\n",
    "Let's create functions to handle this conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bd03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point\n",
    "import tifffile\n",
    "\n",
    "def read_geojson(geojson_path):\n",
    "    \"\"\"Read a GeoJSON file containing annotations.\"\"\"\n",
    "    with open(geojson_path) as f:\n",
    "        geojson = json.load(f)\n",
    "    return geojson\n",
    "\n",
    "def geojson_to_mask(geojson, img_shape, class_mapping=None):\n",
    "    \"\"\"Convert GeoJSON annotations to instance and type masks.\"\"\"\n",
    "    instance_mask = np.zeros(img_shape[:2], dtype=np.int32)\n",
    "    type_mask = np.zeros(img_shape[:2], dtype=np.int32)\n",
    "    \n",
    "    instance_id = 1  # Start with ID 1 (0 is background)\n",
    "    \n",
    "    for feature in geojson['features']:\n",
    "        cell_type = feature['properties'].get('classification', {}).get('name', 'unknown')\n",
    "        type_id = class_mapping.get(cell_type, 0) if class_mapping else 1\n",
    "        \n",
    "        # Get polygon coordinates\n",
    "        if feature['geometry']['type'] == 'Polygon':\n",
    "            coords = feature['geometry']['coordinates'][0]\n",
    "            # Convert to integer coordinates for cv2\n",
    "            coords = np.array(coords, dtype=np.int32)\n",
    "            \n",
    "            # Create instance mask\n",
    "            cv2.fillPoly(instance_mask, [coords], instance_id)\n",
    "            \n",
    "            # Create type mask for the same region\n",
    "            cv2.fillPoly(type_mask, [coords], type_id)\n",
    "            \n",
    "            instance_id += 1\n",
    "    \n",
    "    return instance_mask, type_mask\n",
    "\n",
    "def extract_patches(image, instance_mask, type_mask, patch_size=270, stride=80):\n",
    "    \"\"\"Extract patches from image and corresponding masks.\"\"\"\n",
    "    patches = []\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            img_patch = image[y:y+patch_size, x:x+patch_size].copy()\n",
    "            inst_patch = instance_mask[y:y+patch_size, x:x+patch_size].copy()\n",
    "            type_patch = type_mask[y:y+patch_size, x:x+patch_size].copy()\n",
    "            \n",
    "            # Only keep patches with some nuclei\n",
    "            if np.max(inst_patch) > 0:\n",
    "                # Relabel instance IDs to be consecutive starting from 1\n",
    "                unique_ids = np.unique(inst_patch)\n",
    "                unique_ids = unique_ids[unique_ids > 0]  # Skip background\n",
    "                mapping = {old_id: new_id for new_id, old_id in enumerate(unique_ids, 1)}\n",
    "                mapping[0] = 0  # Keep background as 0\n",
    "                \n",
    "                for old_id, new_id in mapping.items():\n",
    "                    inst_patch[inst_patch == old_id] = new_id\n",
    "                \n",
    "                # Store patch with format [RGB, inst, type]\n",
    "                patch_data = np.dstack([img_patch, inst_patch[..., None], type_patch[..., None]])\n",
    "                patches.append(patch_data)\n",
    "    \n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33757819",
   "metadata": {},
   "source": [
    "### Define Nuclear Type Mapping\n",
    "\n",
    "We need to define how cell types in the PUMA dataset map to type IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1480c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 1 (3 classes) mapping\n",
    "track1_mapping = {\n",
    "    'tumor': 1,\n",
    "    'lymphocyte': 2,  # TIL\n",
    "    'plasma': 2,      # TIL\n",
    "    'histiocyte': 3,  # Other\n",
    "    'melanophage': 3, # Other\n",
    "    'neutrophil': 3,  # Other\n",
    "    'stromal': 3,     # Other\n",
    "    'epithelium': 3,  # Other\n",
    "    'endothelium': 3, # Other\n",
    "    'apoptotic': 3,   # Other\n",
    "    'unknown': 0      # Background\n",
    "}\n",
    "\n",
    "# Track 2 (10 classes) mapping\n",
    "track2_mapping = {\n",
    "    'tumor': 1,\n",
    "    'lymphocyte': 2,\n",
    "    'plasma': 3,\n",
    "    'histiocyte': 4,\n",
    "    'melanophage': 5,\n",
    "    'neutrophil': 6,\n",
    "    'stromal': 7,\n",
    "    'epithelium': 8,\n",
    "    'endothelium': 9,\n",
    "    'apoptotic': 10,\n",
    "    'unknown': 0     # Background\n",
    "}\n",
    "\n",
    "# For tissue segmentation\n",
    "tissue_mapping = {\n",
    "    'tumor': 1,\n",
    "    'stroma': 2,\n",
    "    'epithelium': 3,\n",
    "    'blood_vessel': 4,\n",
    "    'necrosis': 5,\n",
    "    'unknown': 0     # Background\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6096",
   "metadata": {},
   "source": [
    "### Process Data to HoVer-Net Format\n",
    "\n",
    "Let's create a function to process the dataset and save the patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(output_dir, class_mapping, track_name=\"track1\"):\n",
    "    \"\"\"Process the PUMA dataset and create patches for HoVer-Net training.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of ROI images\n",
    "    roi_files = sorted(glob.glob(os.path.join(roi_images_path, \"*.tif\")))\n",
    "    \n",
    "    for i, roi_file in enumerate(roi_files):\n",
    "        roi_filename = os.path.basename(roi_file)\n",
    "        roi_id = roi_filename.split('.')[0]  # Extract ID without extension\n",
    "        \n",
    "        print(f\"Processing {i+1}/{len(roi_files)}: {roi_id}\")\n",
    "        \n",
    "        # Find corresponding annotation file\n",
    "        nuclei_geojson_file = os.path.join(nuclei_annotations_path, f\"{roi_id}_nuclei.geojson\")\n",
    "        \n",
    "        if not os.path.exists(nuclei_geojson_file):\n",
    "            print(f\"WARNING: No annotation found for {roi_id}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Load image and annotations\n",
    "        image = tifffile.imread(roi_file)\n",
    "        geojson = read_geojson(nuclei_geojson_file)\n",
    "        \n",
    "        # Convert annotations to masks\n",
    "        instance_mask, type_mask = geojson_to_mask(geojson, image.shape, class_mapping)\n",
    "        \n",
    "        # Extract patches\n",
    "        patches = extract_patches(image, instance_mask, type_mask)\n",
    "        \n",
    "        # Save patches\n",
    "        for j, patch in enumerate(patches):\n",
    "            patch_filename = f\"{roi_id}_patch_{j}.npy\"\n",
    "            np.save(os.path.join(output_dir, patch_filename), patch)\n",
    "            \n",
    "        # If processing too many ROIs at once, consider adding a limit\n",
    "        # if i >= 10:\n",
    "        #     break\n",
    "    \n",
    "    print(f\"Finished processing {track_name}. Total patches saved: {len(glob.glob(os.path.join(output_dir, '*.npy')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c194fef",
   "metadata": {},
   "source": [
    "### Run Data Processing\n",
    "\n",
    "Let's create patches for both Track 1 and Track 2. Note that this may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f409a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output directories\n",
    "track1_patches_dir = \"./processed_data/track1_patches\"\n",
    "track2_patches_dir = \"./processed_data/track2_patches\"\n",
    "\n",
    "# Process data for Track 1 - uncomment to run\n",
    "# process_dataset(track1_patches_dir, track1_mapping, \"track1\")\n",
    "\n",
    "# Process data for Track 2 - uncomment to run\n",
    "# process_dataset(track2_patches_dir, track2_mapping, \"track2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf703b",
   "metadata": {},
   "source": [
    "### Split Data into Training and Validation Sets\n",
    "\n",
    "Next, we'll split our processed patches into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95c4a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_train_val(input_dir, train_dir, val_dir, val_ratio=0.2):\n",
    "    \"\"\"Split patches into training and validation sets.\"\"\"\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    all_patches = glob.glob(os.path.join(input_dir, \"*.npy\"))\n",
    "    \n",
    "    # Group patches by ROI ID to ensure patches from same ROI stay in same split\n",
    "    roi_groups = {}\n",
    "    for patch_path in all_patches:\n",
    "        patch_name = os.path.basename(patch_path)\n",
    "        roi_id = patch_name.split('_patch_')[0]\n",
    "        if roi_id not in roi_groups:\n",
    "            roi_groups[roi_id] = []\n",
    "        roi_groups[roi_id].append(patch_path)\n",
    "    \n",
    "    # Split ROIs into train and validation\n",
    "    all_rois = list(roi_groups.keys())\n",
    "    random.shuffle(all_rois)\n",
    "    val_size = int(len(all_rois) * val_ratio)\n",
    "    val_rois = all_rois[:val_size]\n",
    "    train_rois = all_rois[val_size:]\n",
    "    \n",
    "    # Copy files\n",
    "    for roi in train_rois:\n",
    "        for patch_path in roi_groups[roi]:\n",
    "            patch_name = os.path.basename(patch_path)\n",
    "            shutil.copy(patch_path, os.path.join(train_dir, patch_name))\n",
    "    \n",
    "    for roi in val_rois:\n",
    "        for patch_path in roi_groups[roi]:\n",
    "            patch_name = os.path.basename(patch_path)\n",
    "            shutil.copy(patch_path, os.path.join(val_dir, patch_name))\n",
    "    \n",
    "    print(f\"Training set: {len(glob.glob(os.path.join(train_dir, '*.npy')))} patches from {len(train_rois)} ROIs\")\n",
    "    print(f\"Validation set: {len(glob.glob(os.path.join(val_dir, '*.npy')))} patches from {len(val_rois)} ROIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9834697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories for train/val splits\n",
    "track1_train_dir = \"./processed_data/track1_train\"\n",
    "track1_val_dir = \"./processed_data/track1_val\"\n",
    "track2_train_dir = \"./processed_data/track2_train\"\n",
    "track2_val_dir = \"./processed_data/track2_val\"\n",
    "\n",
    "# Uncomment to run the splits\n",
    "split_train_val(track1_patches_dir, track1_train_dir, track1_val_dir)\n",
    "# split_train_val(track2_patches_dir, track2_train_dir, track2_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29314c",
   "metadata": {},
   "source": [
    "## 4. Configure HoVer-Net for PUMA Dataset\n",
    "\n",
    "Now we need to create custom configuration files for HoVer-Net that specify our PUMA dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8229c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PUMA dataset class for Track 1 (3 classes)\n",
    "puma_track1_definition = \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def get_puma_track1():\n",
    "    return {\n",
    "        'hash': 'puma_track1',\n",
    "        'name': 'puma_track1',\n",
    "        'import_prep_func': None,\n",
    "        'input_path': './processed_data/track1_train/',\n",
    "        'split_info': {\n",
    "            'train': {\n",
    "                'input': './processed_data/track1_train/*.npy',\n",
    "            },\n",
    "            'valid': {\n",
    "                'input': './processed_data/track1_val/*.npy',\n",
    "            },\n",
    "        },\n",
    "        'type_info': {\n",
    "            0: ['background', [0, 0, 0]],\n",
    "            1: ['tumor', [255, 0, 0]],\n",
    "            2: ['TILs', [0, 255, 0]],\n",
    "            3: ['other', [0, 0, 255]],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def get_puma_track2():\n",
    "\n",
    "    return {\n",
    "        'hash': 'puma_track2',\n",
    "        'name': 'puma_track2',\n",
    "        'import_prep_func': None,\n",
    "        'input_path': './processed_data/track2_train/',\n",
    "        'split_info': {\n",
    "            'train': {\n",
    "                'input': './processed_data/track2_train/*.npy',\n",
    "            },\n",
    "            'valid': {\n",
    "                'input': './processed_data/track2_val/*.npy',\n",
    "            },\n",
    "        },\n",
    "        'type_info': {\n",
    "            0: ['background', [0, 0, 0]],\n",
    "            1: ['tumor', [255, 0, 0]],\n",
    "            2: ['lymphocyte', [0, 255, 0]],\n",
    "            3: ['plasma', [0, 0, 255]],\n",
    "            4: ['histiocyte', [255, 255, 0]],\n",
    "            5: ['melanophage', [255, 0, 255]],\n",
    "            6: ['neutrophil', [0, 255, 255]],\n",
    "            7: ['stromal', [128, 0, 0]],\n",
    "            8: ['epithelium', [0, 128, 0]],\n",
    "            9: ['endothelium', [0, 0, 128]],\n",
    "            10: ['apoptotic', [128, 128, 128]],\n",
    "        },\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Save the custom dataset definitions\n",
    "with open(\"./hover_net/custom_puma_dataset.py\", \"w\") as f:\n",
    "    f.write(puma_track1_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2947668",
   "metadata": {},
   "source": [
    "### Modify HoVer-Net Dataset Configuration\n",
    "\n",
    "We need to register our custom dataset in the main dataset.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c700a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update dataset.py to include our custom dataset\n",
    "def update_dataset_file():\n",
    "    dataset_path = \"./hover_net/dataset.py\"\n",
    "    \n",
    "    # Read the original file\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Check if our dataset is already registered\n",
    "    if \"from custom_puma_dataset import get_puma_track1, get_puma_track2\" in content:\n",
    "        print(\"PUMA datasets already registered in dataset.py\")\n",
    "        return\n",
    "    \n",
    "    # Add import at the beginning\n",
    "    import_line = \"from custom_puma_dataset import get_puma_track1, get_puma_track2\\n\"\n",
    "    # Look for other imports and add after them\n",
    "    import_block_end = content.find(\"def get_dataset\")\n",
    "    if import_block_end > 0:\n",
    "        content = content[:import_block_end] + import_line + content[import_block_end:]\n",
    "    \n",
    "    # Find the dataset_info dictionary and add our datasets\n",
    "    dataset_dict_start = content.find(\"dataset_info = {\")\n",
    "    if dataset_dict_start > 0:\n",
    "        dataset_dict_end = content.find(\"}\", dataset_dict_start)\n",
    "        if dataset_dict_end > 0:\n",
    "            new_entries = \"\"\"\n",
    "    \"puma_track1\": get_puma_track1(),\n",
    "    \"puma_track2\": get_puma_track2(),\"\"\"\n",
    "            content = content[:dataset_dict_end] + new_entries + content[dataset_dict_end:]\n",
    "    \n",
    "    # Write back to file\n",
    "    with open(dataset_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(\"Updated dataset.py with PUMA dataset configurations\")\n",
    "\n",
    "# Update the dataset file\n",
    "update_dataset_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbb1b4",
   "metadata": {},
   "source": [
    "### Create Custom Configuration Files\n",
    "\n",
    "Now let's create a custom configuration file for PUMA training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_config(track_id=1, nr_classes=4):\n",
    "    \"\"\"\n",
    "    Create a custom config file for HoVer-Net training on PUMA dataset.\n",
    "    track_id: 1 or 2 (corresponding to Track 1 or Track 2)\n",
    "    nr_classes: number of classes including background (4 for track1, 11 for track2)\n",
    "    \"\"\"\n",
    "    config_content = f\"\"\"\n",
    "import importlib\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dataset import get_dataset\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.seed = 10\n",
    "        self.logging = True\n",
    "        self.debug = False\n",
    "        \n",
    "        model_name = \"hovernet\"\n",
    "        model_mode = \"original\"  # original or fast\n",
    "        \n",
    "        # Number of nuclear types (including background)\n",
    "        nr_type = {nr_classes}  # {nr_classes-1} classes + background\n",
    "        \n",
    "        # Whether to predict the nuclear type\n",
    "        self.type_classification = True\n",
    "        \n",
    "        # Shape information\n",
    "        aug_shape = [540, 540]  # patch shape used during augmentation\n",
    "        act_shape = [270, 270]  # patch shape used as input to network\n",
    "        out_shape = [80, 80]    # patch shape at output of network\n",
    "        \n",
    "        # Dataset name\n",
    "        self.dataset_name = \"puma_track{track_id}\"\n",
    "        \n",
    "        # Log directory for checkpoints\n",
    "        self.log_dir = \"logs/puma_track{track_id}/\"\n",
    "        \n",
    "        # Paths to training and validation patches\n",
    "        self.train_dir_list = [\n",
    "            \"./processed_data/track{track_id}_train\"\n",
    "        ]\n",
    "        self.valid_dir_list = [\n",
    "            \"./processed_data/track{track_id}_val\"\n",
    "        ]\n",
    "        \n",
    "        self.shape_info = {{\n",
    "            \"train\": {{\n",
    "                \"input_shape\": act_shape,\n",
    "                \"mask_shape\": out_shape,\n",
    "            }},\n",
    "            \"valid\": {{\n",
    "                \"input_shape\": act_shape,\n",
    "                \"mask_shape\": out_shape,\n",
    "            }},\n",
    "        }}\n",
    "        \n",
    "        # Parse config to the running state and set up associated variables\n",
    "        self.dataset = get_dataset(self.dataset_name)\n",
    "        module = importlib.import_module(\n",
    "            \"models.%s.opt\" % model_name\n",
    "        )\n",
    "        self.model_config = module.get_config(nr_type, model_mode)\n",
    "    \"\"\"\n",
    "    \n",
    "    config_path = f\"./hover_net/puma_track{track_id}_config.py\"\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"Created custom config file at {config_path}\")\n",
    "\n",
    "# Create config files for both tracks\n",
    "create_custom_config(track_id=1, nr_classes=4)  # Track 1: background + 3 classes\n",
    "# create_custom_config(track_id=2, nr_classes=11)  # Track 2: background + 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a4510",
   "metadata": {},
   "source": [
    "## 5. Training HoVer-Net\n",
    "\n",
    "With our data prepared and configuration files created, we're now ready to train HoVer-Net for the PUMA challenge. We'll train separate models for Track 1 and Track 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from train_utils import train_hovernet\n",
    "\n",
    "# Import the improved training utility\n",
    "print(\"Using improved training utility from train_utils.py\")\n",
    "\n",
    "# Train for Track 1 (uncomment to run)\n",
    "train_hovernet(track_id=1, gpu_ids=\"0\", epochs=50, batch_size=8, lr=1e-4)\n",
    "\n",
    "# For Track 2 - uncomment and run when needed\n",
    "# train_hovernet(track_id=2, gpu_ids=\"0\", epochs=50, batch_size=8, lr=1e-4)\n",
    "\n",
    "# You can also run training from the command line with:\n",
    "# python train_utils.py --track 1 --gpu 0 --epochs 50 --batch-size 8 --lr 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fc625",
   "metadata": {},
   "source": [
    "### Monitor Training Progress\n",
    "\n",
    "After starting the training, we can monitor its progress through TensorBoard logs. HoVer-Net training saves logs in the specified log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63130ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard (uncomment to run)\n",
    "# %tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7f6a0",
   "metadata": {},
   "source": [
    "## 6. Inference with Trained Models\n",
    "\n",
    "After training, we can use the trained models to make predictions on new images. HoVer-Net provides a script for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(track_id=1, gpu_ids=\"0\"):\n",
    "    \"\"\"Run inference using a trained HoVer-Net model.\"\"\"\n",
    "    # Path to the trained model checkpoint\n",
    "    checkpoint_path = f\"./logs/puma_track{track_id}/hovernet_epoch=50.tar\"\n",
    "    \n",
    "    # Path to test images\n",
    "    test_dir = f\"./test_images\"\n",
    "    output_dir = f\"./results/track{track_id}\"\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    nr_types = 4 if track_id == 1 else 11\n",
    "    \n",
    "    # Command to run inference\n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        \"./hover_net/run_infer.py\",\n",
    "        \"tile\",\n",
    "        f\"--gpu={gpu_ids}\",\n",
    "        f\"--nr_types={nr_types}\",\n",
    "        f\"--model_path={checkpoint_path}\",\n",
    "        \"--model_mode=original\",\n",
    "        f\"--input_dir={test_dir}\",\n",
    "        f\"--output_dir={output_dir}\",\n",
    "        \"--save_qupath\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running inference with PUMA Track {track_id} model...\")\n",
    "    print(f\"Using GPUs: {gpu_ids}\")\n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the inference script\n",
    "        # In a real execution, you would uncomment the following:\n",
    "        # result = subprocess.run(cmd, check=True)\n",
    "        # print(f\"Inference completed with exit code {result.returncode}\")\n",
    "        print(\"[Simulated] Inference would start here. In a real execution, uncomment the subprocess.run call.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Inference failed with error: {e}\")\n",
    "\n",
    "# Run inference with Track 1 model (uncomment to run)\n",
    "# run_inference(track_id=1, gpu_ids=\"0\")\n",
    "\n",
    "# Run inference with Track 2 model (uncomment to run)\n",
    "# run_inference(track_id=2, gpu_ids=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca0e00",
   "metadata": {},
   "source": [
    "## 7. Evaluate Results\n",
    "\n",
    "Finally, we can evaluate the performance of our trained models on the validation set using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(track_id=1):\n",
    "    \"\"\"Evaluate the trained model using metrics from HoVer-Net.\"\"\"\n",
    "    # Path to the results directory\n",
    "    results_dir = f\"./results/track{track_id}\"\n",
    "    \n",
    "    # Command to compute metrics\n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        \"./hover_net/compute_stats.py\",\n",
    "        f\"--pred_dir={results_dir}\",\n",
    "        f\"--true_dir=./processed_data/track{track_id}_val\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Computing metrics for PUMA Track {track_id} model...\")\n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the metrics computation script\n",
    "        # In a real execution, you would uncomment the following:\n",
    "        # result = subprocess.run(cmd, check=True)\n",
    "        # print(f\"Metrics computation completed with exit code {result.returncode}\")\n",
    "        print(\"[Simulated] Metrics computation would start here. In a real execution, uncomment the subprocess.run call.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Metrics computation failed with error: {e}\")\n",
    "\n",
    "# Evaluate Track 1 model (uncomment to run)\n",
    "# evaluate_model(track_id=1)\n",
    "\n",
    "# Evaluate Track 2 model (uncomment to run)\n",
    "# evaluate_model(track_id=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82997f1e",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the process of training HoVer-Net models for the PUMA challenge tasks. The steps included:\n",
    "\n",
    "1. Exploring and understanding the PUMA dataset\n",
    "2. Converting GeoJSON annotations to the format required by HoVer-Net\n",
    "3. Processing images and generating patches for training\n",
    "4. Creating custom configurations for HoVer-Net\n",
    "5. Training separate models for Track 1 (3 classes) and Track 2 (10 classes)\n",
    "6. Running inference on new images\n",
    "7. Evaluating model performance with metrics\n",
    "\n",
    "HoVer-Net's architecture, with its dedicated branches for segmentation and classification, is well-suited for the PUMA challenge which requires both accurate nuclei segmentation and classification.\n",
    "\n",
    "To improve results, consider the following:\n",
    "- Try different data augmentation techniques\n",
    "- Adjust learning rates and training epochs\n",
    "- Experiment with different model configurations (original vs. fast mode)\n",
    "- Explore ensemble methods by combining predictions from multiple models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
