{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b91849",
   "metadata": {},
   "source": [
    "# PUMA Challenge - Training HoVer-Net\n",
    "\n",
    "This notebook demonstrates how to train the HoVer-Net model for the Panoptic Segmentation of nUclei and tissue in advanced MelanomA (PUMA) challenge. \n",
    "\n",
    "## PUMA Challenge Overview\n",
    "\n",
    "The PUMA challenge consists of two tracks, each with two tasks:\n",
    "\n",
    "### Track 1 – Panoptic segmentation with three instance classes:\n",
    "- **Task 1**: Semantic tissue segmentation of tumor, stroma, epithelium, blood vessel, and necrotic regions.\n",
    "- **Task 2**: Nuclei detection for three classes; tumor, TILs (lymphocytes and plasma cells), and other cells.\n",
    "\n",
    "### Track 2 – Panoptic segmentation with ten instance classes:\n",
    "- **Task 1**: Semantic tissue segmentation (same as Track 1).\n",
    "- **Task 2**: Nuclei detection for all ten classes: tumor, lymphocytes, plasma cells, histiocytes, melanophages, neutrophils, stromal cells, epithelium, endothelium, and apoptotic cells.\n",
    "\n",
    "In this notebook, we'll focus on training HoVer-Net for both tracks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce01efdc",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's set up our environment and import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "769f4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "import concurrent.futures  # Added for multi-threading\n",
    "\n",
    "# Add HoVer-Net directory to path\n",
    "sys.path.append('./hover_net/')\n",
    "\n",
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac8b8d6",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Understanding\n",
    "\n",
    "The PUMA dataset consists of:\n",
    "- 155 primary and 155 metastatic melanoma regions of interest (ROI), scanned at 40x magnification (1024 x 1024 pixels)\n",
    "- Context ROI of 5120 x 5120 pixels, centered around each ROI\n",
    "- Annotations for tissue and nuclei\n",
    "\n",
    "Let's explore the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "912bd4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nuclei annotation files: 205\n",
      "Number of tissue annotation files: 205\n",
      "Number of ROI image files: 205\n",
      "Number of context ROI image files: 205\n",
      "\n",
      "Sample nuclei annotation files:\n",
      "  - training_set_metastatic_roi_080_nuclei.geojson\n",
      "  - training_set_metastatic_roi_049_nuclei.geojson\n",
      "  - training_set_primary_roi_023_nuclei.geojson\n",
      "  - training_set_metastatic_roi_029_nuclei.geojson\n",
      "  - training_set_metastatic_roi_065_nuclei.geojson\n"
     ]
    }
   ],
   "source": [
    "# Define dataset paths\n",
    "dataset_path = \"../dataset\"\n",
    "\n",
    "# List available ROIs\n",
    "nuclei_annotations_path = os.path.join(dataset_path, \"01_training_dataset_geojson_nuclei\")\n",
    "tissue_annotations_path = os.path.join(dataset_path, \"01_training_dataset_geojson_tissue\")\n",
    "roi_images_path = os.path.join(dataset_path, \"01_training_dataset_tif_ROIs\")\n",
    "context_roi_path = os.path.join(dataset_path, \"01_training_dataset_tif_context_ROIs\")\n",
    "\n",
    "# Count the number of files in each directory\n",
    "print(f\"Number of nuclei annotation files: {len(os.listdir(nuclei_annotations_path))}\")\n",
    "print(f\"Number of tissue annotation files: {len(os.listdir(tissue_annotations_path))}\")\n",
    "print(f\"Number of ROI image files: {len(os.listdir(roi_images_path))}\")\n",
    "print(f\"Number of context ROI image files: {len(os.listdir(context_roi_path))}\")\n",
    "\n",
    "# Look at sample filenames\n",
    "print(\"\\nSample nuclei annotation files:\")\n",
    "for file in os.listdir(nuclei_annotations_path)[:5]:\n",
    "    print(f\"  - {file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2195285",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "HoVer-Net requires the data in a specific format. For training, we need to:\n",
    "1. Convert GeoJSON annotations to instance masks\n",
    "2. Extract patches from original images\n",
    "3. Format data as required by HoVer-Net: [RGB, inst, type] channels\n",
    "\n",
    "Let's create functions to handle this conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bd03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon, Point\n",
    "import tifffile\n",
    "import multiprocessing  # For CPU-bound operations\n",
    "\n",
    "\n",
    "def read_geojson(geojson_path):\n",
    "    \"\"\"Read a GeoJSON file containing annotations.\"\"\"\n",
    "    with open(geojson_path) as f:\n",
    "        geojson = json.load(f)\n",
    "    return geojson\n",
    "\n",
    "\n",
    "def geojson_to_mask_optimized(geojson, img_shape, class_mapping=None):\n",
    "    \"\"\"Convert GeoJSON annotations to instance and type masks with optimizations.\"\"\"\n",
    "    instance_mask = np.zeros(img_shape[:2], dtype=np.int32)\n",
    "    type_mask = np.zeros(img_shape[:2], dtype=np.int32)\n",
    "\n",
    "    # Pre-allocate arrays for better performance\n",
    "    all_polygons = []\n",
    "    all_instance_ids = []\n",
    "    all_type_ids = []\n",
    "    instance_id = 1  # Start with ID 1 (0 is background)\n",
    "\n",
    "    # First, collect all polygons and their IDs\n",
    "    for feature in geojson[\"features\"]:\n",
    "        cell_type = (\n",
    "            feature[\"properties\"].get(\"classification\", {}).get(\"name\", \"unknown\")\n",
    "        )\n",
    "        type_id = class_mapping.get(cell_type, 0) if class_mapping else 1\n",
    "\n",
    "        # Get polygon coordinates\n",
    "        if feature[\"geometry\"][\"type\"] == \"Polygon\":\n",
    "            coords = feature[\"geometry\"][\"coordinates\"][0]\n",
    "            # Convert to integer coordinates for cv2\n",
    "            coords = np.array(coords, dtype=np.int32)\n",
    "\n",
    "            all_polygons.append(coords)\n",
    "            all_instance_ids.append(instance_id)\n",
    "            all_type_ids.append(type_id)\n",
    "\n",
    "            instance_id += 1\n",
    "\n",
    "    # Fill all polygons at once when possible\n",
    "    if len(all_polygons) > 0:\n",
    "        # Process in batches to avoid memory issues with very large datasets\n",
    "        batch_size = 1000  # Adjust based on memory constraints\n",
    "        for i in range(0, len(all_polygons), batch_size):\n",
    "            batch_polygons = all_polygons[i : i + batch_size]\n",
    "            batch_instance_ids = all_instance_ids[i : i + batch_size]\n",
    "            batch_type_ids = all_type_ids[i : i + batch_size]\n",
    "\n",
    "            for polygon, inst_id, type_id in zip(\n",
    "                batch_polygons, batch_instance_ids, batch_type_ids\n",
    "            ):\n",
    "                cv2.fillPoly(instance_mask, [polygon], inst_id)\n",
    "                cv2.fillPoly(type_mask, [polygon], type_id)\n",
    "\n",
    "    return instance_mask, type_mask\n",
    "\n",
    "\n",
    "def extract_patches_optimized(\n",
    "    image,\n",
    "    instance_mask,\n",
    "    type_mask,\n",
    "    patch_size=270,\n",
    "    stride=80,\n",
    "    min_nuclei_percentage=0.05,\n",
    "):\n",
    "    \"\"\"Extract patches more efficiently with parallel processing.\"\"\"\n",
    "    patches = []\n",
    "    coords = []\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Generate all potential patch coordinates\n",
    "    patch_coords = []\n",
    "    for y in range(0, h - patch_size + 1, stride):\n",
    "        for x in range(0, w - patch_size + 1, stride):\n",
    "            patch_coords.append((y, x))\n",
    "\n",
    "    def process_patch(coord):\n",
    "        y, x = coord\n",
    "        inst_patch = instance_mask[y : y + patch_size, x : x + patch_size].copy()\n",
    "\n",
    "        # Skip patches with no or few nuclei\n",
    "        if np.max(inst_patch) == 0:\n",
    "            return None\n",
    "\n",
    "        # Skip if less than min_nuclei_percentage of patch has nuclei\n",
    "        nuclei_pixels = np.sum(inst_patch > 0)\n",
    "        total_pixels = patch_size * patch_size\n",
    "        if nuclei_pixels / total_pixels < min_nuclei_percentage:\n",
    "            return None\n",
    "\n",
    "        img_patch = image[y : y + patch_size, x : x + patch_size].copy()\n",
    "        type_patch = type_mask[y : y + patch_size, x : x + patch_size].copy()\n",
    "\n",
    "        # Relabel instance IDs to be consecutive\n",
    "        unique_ids = np.unique(inst_patch)\n",
    "        unique_ids = unique_ids[unique_ids > 0]  # Skip background\n",
    "\n",
    "        # Fast relabeling\n",
    "        if len(unique_ids) > 0:\n",
    "            remap = np.zeros(np.max(inst_patch) + 1, dtype=np.int32)\n",
    "            remap[unique_ids] = np.arange(1, len(unique_ids) + 1)\n",
    "            inst_patch = remap[inst_patch]\n",
    "\n",
    "        # Stack data efficiently\n",
    "        patch_data = np.dstack(\n",
    "            [img_patch, inst_patch[..., None], type_patch[..., None]]\n",
    "        )\n",
    "        return patch_data\n",
    "\n",
    "    # Process patches in parallel\n",
    "    for patch in patch_coords:\n",
    "        result = process_patch(patch)\n",
    "        if result is not None:\n",
    "            patches.append(result)\n",
    "\n",
    "    return patches\n",
    "\n",
    "\n",
    "def process_single_roi_optimized(\n",
    "    roi_file, output_dir, class_mapping, nuclei_annotations_path\n",
    "):\n",
    "    \"\"\"Process a single ROI image with optimizations.\"\"\"\n",
    "    roi_filename = os.path.basename(roi_file)\n",
    "    roi_id = roi_filename.split(\".\")[0]  # Extract ID without extension\n",
    "\n",
    "    # Find corresponding annotation file\n",
    "    nuclei_geojson_file = os.path.join(\n",
    "        nuclei_annotations_path, f\"{roi_id}_nuclei.geojson\"\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(nuclei_geojson_file):\n",
    "        print(f\"WARNING: No annotation found for {roi_id}, skipping...\")\n",
    "        return 0\n",
    "\n",
    "    # Load image and annotations\n",
    "    image = tifffile.imread(roi_file)\n",
    "    geojson = read_geojson(nuclei_geojson_file)\n",
    "\n",
    "    # Convert annotations to masks using optimized function\n",
    "    instance_mask, type_mask = geojson_to_mask_optimized(\n",
    "        geojson, image.shape, class_mapping\n",
    "    )\n",
    "\n",
    "    # Extract patches using optimized function\n",
    "    patches = extract_patches_optimized(image, instance_mask, type_mask)\n",
    "\n",
    "    # Save patches in parallel\n",
    "    def save_patch(args):\n",
    "        j, patch = args\n",
    "        patch_filename = f\"{roi_id}_patch_{j}.npz\"\n",
    "        filepath = os.path.join(output_dir, patch_filename)\n",
    "        np.savez_compressed(filepath, patch)\n",
    "\n",
    "    for i, patch in enumerate(patches):\n",
    "        save_patch((i, patch))\n",
    "\n",
    "    return len(patches)\n",
    "\n",
    "\n",
    "def process_dataset_optimized(output_dir, class_mapping, track_name, max_workers=None):\n",
    "    \"\"\"Process the PUMA dataset with optimized multiprocessing.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Automatically determine optimal number of workers\n",
    "    if max_workers is None:\n",
    "        max_workers = os.cpu_count()\n",
    "\n",
    "    # Get list of ROI images\n",
    "    roi_files = sorted(glob.glob(os.path.join(roi_images_path, \"*.tif\")))\n",
    "\n",
    "    print(f\"Starting multiprocessing with {max_workers} workers...\")\n",
    "\n",
    "    # Prepare arguments for multiprocessing\n",
    "    process_args = [\n",
    "        (roi_file, output_dir, class_mapping, nuclei_annotations_path)\n",
    "        for roi_file in roi_files\n",
    "    ]\n",
    "\n",
    "    # Use multiprocessing instead of threading for CPU-bound tasks\n",
    "    with multiprocessing.Pool(processes=max_workers) as pool:\n",
    "        results = []\n",
    "        for i, num_patches in enumerate(\n",
    "            pool.starmap(process_single_roi_optimized, process_args)\n",
    "        ):\n",
    "            roi_id = os.path.basename(roi_files[i]).split(\".\")[0]\n",
    "            print(\n",
    "                f\"Processed {i+1}/{len(roi_files)}: {roi_id} - {num_patches} patches extracted\"\n",
    "            )\n",
    "            results.append(num_patches)\n",
    "\n",
    "    total_patches = sum(results)\n",
    "    print(f\"Finished processing {track_name}. Total patches saved: {total_patches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33757819",
   "metadata": {},
   "source": [
    "### Define Nuclear Type Mapping\n",
    "\n",
    "We need to define how cell types in the PUMA dataset map to type IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1480c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track 1 (3 classes) mapping\n",
    "track1_mapping = {\n",
    "    'tumor': 1,\n",
    "    'lymphocyte': 2,  # TIL\n",
    "    'plasma': 2,      # TIL\n",
    "    'histiocyte': 3,  # Other\n",
    "    'melanophage': 3, # Other\n",
    "    'neutrophil': 3,  # Other\n",
    "    'stromal': 3,     # Other\n",
    "    'epithelium': 3,  # Other\n",
    "    'endothelium': 3, # Other\n",
    "    'apoptotic': 3,   # Other\n",
    "    'unknown': 0      # Background\n",
    "}\n",
    "\n",
    "# Track 2 (10 classes) mapping\n",
    "track2_mapping = {\n",
    "    'tumor': 1,\n",
    "    'lymphocyte': 2,\n",
    "    'plasma': 3,\n",
    "    'histiocyte': 4,\n",
    "    'melanophage': 5,\n",
    "    'neutrophil': 6,\n",
    "    'stromal': 7,\n",
    "    'epithelium': 8,\n",
    "    'endothelium': 9,\n",
    "    'apoptotic': 10,\n",
    "    'unknown': 0     # Background\n",
    "}\n",
    "\n",
    "# For tissue segmentation\n",
    "tissue_mapping = {\n",
    "    'tumor': 1,\n",
    "    'stroma': 2,\n",
    "    'epithelium': 3,\n",
    "    'blood_vessel': 4,\n",
    "    'necrosis': 5,\n",
    "    'unknown': 0     # Background\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be6096",
   "metadata": {},
   "source": [
    "### Process Data to HoVer-Net Format\n",
    "\n",
    "Let's create a function to process the dataset and save the patches:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c194fef",
   "metadata": {},
   "source": [
    "### Run Data Processing\n",
    "\n",
    "Let's create patches for both Track 1 and Track 2. Note that this may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f409a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting multiprocessing with 20 workers...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m track2_patches_dir = \u001b[33m\"\u001b[39m\u001b[33m./processed_data/track2_patches\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Process data for Track 1 with multi-threading\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Adjust max_workers based on your CPU cores (default: 8)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mprocess_dataset_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack1_patches_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack1_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrack1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Process data for Track 2 - uncomment to run\u001b[39;00m\n\u001b[32m     10\u001b[39m process_dataset_optimized(track2_patches_dir, track2_mapping, \u001b[33m\"\u001b[39m\u001b[33mtrack2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 190\u001b[39m, in \u001b[36mprocess_dataset_optimized\u001b[39m\u001b[34m(output_dir, class_mapping, track_name, max_workers)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing.Pool(processes=max_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    188\u001b[39m     results = []\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, num_patches \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m         \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_single_roi_optimized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     ):\n\u001b[32m    192\u001b[39m         roi_id = os.path.basename(roi_files[i]).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    193\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    194\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(roi_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_patches\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m patches extracted\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    195\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:375\u001b[39m, in \u001b[36mPool.starmap\u001b[39m\u001b[34m(self, func, iterable, chunksize)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    370\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[33;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[33;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[32m    373\u001b[39m \u001b[33;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:768\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    767\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m768\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    769\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ready():\n\u001b[32m    770\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/multiprocessing/pool.py:765\u001b[39m, in \u001b[36mApplyResult.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    764\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_event\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    653\u001b[39m signaled = \u001b[38;5;28mself\u001b[39m._flag\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-linux-x86_64-gnu/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Set output directories\n",
    "track1_patches_dir = \"./processed_data/track1_patches\"\n",
    "track2_patches_dir = \"./processed_data/track2_patches\"\n",
    "\n",
    "# Process data for Track 1 with multi-threading\n",
    "# Adjust max_workers based on your CPU cores (default: 8)\n",
    "process_dataset_optimized(track1_patches_dir, track1_mapping, \"track1\")\n",
    "\n",
    "# Process data for Track 2 - uncomment to run\n",
    "process_dataset_optimized(track2_patches_dir, track2_mapping, \"track2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf703b",
   "metadata": {},
   "source": [
    "### Split Data into Training and Validation Sets\n",
    "\n",
    "Next, we'll split our processed patches into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4a5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_train_val_optimized(input_dir, train_dir, val_dir, val_ratio=0.2):\n",
    "    \"\"\"Split patches into training and validation sets with optimized file operations.\"\"\"\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    all_patches = glob.glob(os.path.join(input_dir, \"*.npy\"))\n",
    "    \n",
    "    # Group patches by ROI ID to ensure patches from same ROI stay in same split\n",
    "    roi_groups = {}\n",
    "    for patch_path in all_patches:\n",
    "        patch_name = os.path.basename(patch_path)\n",
    "        roi_id = patch_name.split('_patch_')[0]\n",
    "        if roi_id not in roi_groups:\n",
    "            roi_groups[roi_id] = []\n",
    "        roi_groups[roi_id].append(patch_path)\n",
    "    \n",
    "    # Split ROIs into train and validation\n",
    "    all_rois = list(roi_groups.keys())\n",
    "    random.shuffle(all_rois)\n",
    "    val_size = int(len(all_rois) * val_ratio)\n",
    "    val_rois = all_rois[:val_size]\n",
    "    train_rois = all_rois[val_size:]\n",
    "    \n",
    "    # Function to copy files in parallel\n",
    "    def copy_files_for_roi(args):\n",
    "        roi, dest_dir = args\n",
    "        copied = 0\n",
    "        for patch_path in roi_groups[roi]:\n",
    "            patch_name = os.path.basename(patch_path)\n",
    "            dest_path = os.path.join(dest_dir, patch_name)\n",
    "            shutil.copy(patch_path, dest_path)\n",
    "            copied += 1\n",
    "        return copied\n",
    "    \n",
    "    # Copy files in parallel\n",
    "    train_args = [(roi, train_dir) for roi in train_rois]\n",
    "    val_args = [(roi, val_dir) for roi in val_rois]\n",
    "    \n",
    "    with multiprocessing.Pool(processes=os.cpu_count()) as pool:\n",
    "        train_copied = sum(pool.map(copy_files_for_roi, train_args))\n",
    "        val_copied = sum(pool.map(copy_files_for_roi, val_args))\n",
    "    \n",
    "    print(f\"Training set: {train_copied} patches from {len(train_rois)} ROIs\")\n",
    "    print(f\"Validation set: {val_copied} patches from {len(val_rois)} ROIs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9834697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 0 patches from 0 ROIs\n",
      "Validation set: 0 patches from 0 ROIs\n"
     ]
    }
   ],
   "source": [
    "# Set directories for train/val splits\n",
    "track1_train_dir = \"./processed_data/track1_train\"\n",
    "track1_val_dir = \"./processed_data/track1_val\"\n",
    "track2_train_dir = \"./processed_data/track2_train\"\n",
    "track2_val_dir = \"./processed_data/track2_val\"\n",
    "\n",
    "# Uncomment to run the splits\n",
    "split_train_val_optimized(track1_patches_dir, track1_train_dir, track1_val_dir)\n",
    "# split_train_val_optimized(track2_patches_dir, track2_train_dir, track2_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29314c",
   "metadata": {},
   "source": [
    "## 4. Configure HoVer-Net for PUMA Dataset\n",
    "\n",
    "Now we need to create custom configuration files for HoVer-Net that specify our PUMA dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229c864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom PUMA dataset class for Track 1 (3 classes)\n",
    "puma_track1_definition = \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_puma_track1():\n",
    "    return {\n",
    "        'hash': 'puma_track1',\n",
    "        'name': 'puma_track1',\n",
    "        'import_prep_func': None,\n",
    "        'input_path': './processed_data/track1_train/',\n",
    "        'split_info': {\n",
    "            'train': {\n",
    "                'input': './processed_data/track1_train/*.npy',\n",
    "            },\n",
    "            'valid': {\n",
    "                'input': './processed_data/track1_val/*.npy',\n",
    "            },\n",
    "        },\n",
    "        'type_info': {\n",
    "            0: ['background', [0, 0, 0]],\n",
    "            1: ['tumor', [255, 0, 0]],\n",
    "            2: ['TILs', [0, 255, 0]],\n",
    "            3: ['other', [0, 0, 255]],\n",
    "        },\n",
    "    }\n",
    "\n",
    "def get_puma_track2():\n",
    "    return {\n",
    "        'hash': 'puma_track2',\n",
    "        'name': 'puma_track2',\n",
    "        'import_prep_func': None,\n",
    "        'input_path': './processed_data/track2_train/',\n",
    "        'split_info': {\n",
    "            'train': {\n",
    "                'input': './processed_data/track2_train/*.npy',\n",
    "            },\n",
    "            'valid': {\n",
    "                'input': './processed_data/track2_val/*.npy',\n",
    "            },\n",
    "        },\n",
    "        'type_info': {\n",
    "            0: ['background', [0, 0, 0]],\n",
    "            1: ['tumor', [255, 0, 0]],\n",
    "            2: ['lymphocyte', [0, 255, 0]],\n",
    "            3: ['plasma', [0, 0, 255]],\n",
    "            4: ['histiocyte', [255, 255, 0]],\n",
    "            5: ['melanophage', [255, 0, 255]],\n",
    "            6: ['neutrophil', [0, 255, 255]],\n",
    "            7: ['stromal', [128, 0, 0]],\n",
    "            8: ['epithelium', [0, 128, 0]],\n",
    "            9: ['endothelium', [0, 0, 128]],\n",
    "            10: ['apoptotic', [128, 128, 128]],\n",
    "        },\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "# Save the custom dataset definitions\n",
    "with open(\"./hover_net/custom_puma_dataset.py\", \"w\") as f:\n",
    "    f.write(puma_track1_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2947668",
   "metadata": {},
   "source": [
    "### Modify HoVer-Net Dataset Configuration\n",
    "\n",
    "We need to register our custom dataset in the main dataset.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c700a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataset.py with PUMA dataset configurations\n"
     ]
    }
   ],
   "source": [
    "# Function to update dataset.py to include our custom dataset\n",
    "def update_dataset_file():\n",
    "    dataset_path = \"./hover_net/dataset.py\"\n",
    "    \n",
    "    # Read the original file\n",
    "    with open(dataset_path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Check if our dataset is already registered\n",
    "    if \"from custom_puma_dataset import get_puma_track1, get_puma_track2\" in content:\n",
    "        print(\"PUMA datasets already registered in dataset.py\")\n",
    "        return\n",
    "    \n",
    "    # Add import at the beginning\n",
    "    import_line = \"from custom_puma_dataset import get_puma_track1, get_puma_track2\\n\"\n",
    "    # Look for other imports and add after them\n",
    "    import_block_end = content.find(\"def get_dataset\")\n",
    "    if import_block_end > 0:\n",
    "        content = content[:import_block_end] + import_line + content[import_block_end:]\n",
    "    \n",
    "    # Find the dataset_info dictionary and add our datasets\n",
    "    dataset_dict_start = content.find(\"dataset_info = {\")\n",
    "    if dataset_dict_start > 0:\n",
    "        dataset_dict_end = content.find(\"}\", dataset_dict_start)\n",
    "        if dataset_dict_end > 0:\n",
    "            new_entries = \"\"\"\n",
    "    \"puma_track1\": get_puma_track1(),\n",
    "    \"puma_track2\": get_puma_track2(),\"\"\"\n",
    "            content = content[:dataset_dict_end] + new_entries + content[dataset_dict_end:]\n",
    "    \n",
    "    # Write back to file\n",
    "    with open(dataset_path, \"w\") as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    print(\"Updated dataset.py with PUMA dataset configurations\")\n",
    "\n",
    "# Update the dataset file\n",
    "update_dataset_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbb1b4",
   "metadata": {},
   "source": [
    "### Create Custom Configuration Files\n",
    "\n",
    "Now let's create a custom configuration file for PUMA training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created custom config file at ./hover_net/puma_track1_config.py\n"
     ]
    }
   ],
   "source": [
    "def create_custom_config(track_id=1, nr_classes=4):\n",
    "    \"\"\"\n",
    "    Create a custom config file for HoVer-Net training on PUMA dataset.\n",
    "    track_id: 1 or 2 (corresponding to Track 1 or Track 2)\n",
    "    nr_classes: number of classes including background (4 for track1, 11 for track2)\n",
    "    \"\"\"\n",
    "    config_content = f\"\"\"\n",
    "import importlib\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from dataset import get_dataset\n",
    "\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.seed = 10\n",
    "        self.logging = True\n",
    "        self.debug = False\n",
    "        \n",
    "        model_name = \"hovernet\"\n",
    "        model_mode = \"original\"  # original or fast\n",
    "        \n",
    "        # Number of nuclear types (including background)\n",
    "        nr_type = {nr_classes}  # {nr_classes-1} classes + background\n",
    "        \n",
    "        # Whether to predict the nuclear type\n",
    "        self.type_classification = True\n",
    "        \n",
    "        # Shape information\n",
    "        aug_shape = [540, 540]  # patch shape used during augmentation\n",
    "        act_shape = [270, 270]  # patch shape used as input to network\n",
    "        out_shape = [80, 80]    # patch shape at output of network\n",
    "        \n",
    "        # Dataset name\n",
    "        self.dataset_name = \"puma_track{track_id}\"\n",
    "        \n",
    "        # Log directory for checkpoints\n",
    "        self.log_dir = \"logs/puma_track{track_id}/\"\n",
    "        \n",
    "        # Paths to training and validation patches\n",
    "        self.train_dir_list = [\n",
    "            \"./processed_data/track{track_id}_train\"\n",
    "        ]\n",
    "        self.valid_dir_list = [\n",
    "            \"./processed_data/track{track_id}_val\"\n",
    "        ]\n",
    "        \n",
    "        self.shape_info = {{\n",
    "            \"train\": {{\n",
    "                \"input_shape\": act_shape,\n",
    "                \"mask_shape\": out_shape,\n",
    "            }},\n",
    "            \"valid\": {{\n",
    "                \"input_shape\": act_shape,\n",
    "                \"mask_shape\": out_shape,\n",
    "            }},\n",
    "        }}\n",
    "        \n",
    "        # Parse config to the running state and set up associated variables\n",
    "        self.dataset = get_dataset(self.dataset_name)\n",
    "        module = importlib.import_module(\n",
    "            \"models.%s.opt\" % model_name\n",
    "        )\n",
    "        self.model_config = module.get_config(nr_type, model_mode)\n",
    "    \"\"\"\n",
    "    \n",
    "    config_path = f\"./hover_net/puma_track{track_id}_config.py\"\n",
    "    with open(config_path, \"w\") as f:\n",
    "        f.write(config_content)\n",
    "    \n",
    "    print(f\"Created custom config file at {config_path}\")\n",
    "\n",
    "# Create config files for both tracks\n",
    "create_custom_config(track_id=1, nr_classes=4)  # Track 1: background + 3 classes\n",
    "# create_custom_config(track_id=2, nr_classes=11)  # Track 2: background + 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a4510",
   "metadata": {},
   "source": [
    "## 5. Training HoVer-Net\n",
    "\n",
    "With our data prepared and configuration files created, we're now ready to train HoVer-Net for the PUMA challenge. We'll train separate models for Track 1 and Track 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb749c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 1 Training Files: 0\n",
      "Track 1 Validation Files: 0\n",
      "Track 2 Training Files: 0\n",
      "Track 2 Validation Files: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if our processed data is available\n",
    "def check_processed_data():\n",
    "    track1_train_files = glob.glob(\"./processed_data/track1_train/*.npy\")\n",
    "    track1_val_files = glob.glob(\"./processed_data/track1_val/*.npy\")\n",
    "    track2_train_files = glob.glob(\"./processed_data/track2_train/*.npy\")\n",
    "    track2_val_files = glob.glob(\"./processed_data/track2_val/*.npy\")\n",
    "    \n",
    "    print(f\"Track 1 Training Files: {len(track1_train_files)}\")\n",
    "    print(f\"Track 1 Validation Files: {len(track1_val_files)}\")\n",
    "    print(f\"Track 2 Training Files: {len(track2_train_files)}\")\n",
    "    print(f\"Track 2 Validation Files: {len(track2_val_files)}\")\n",
    "    \n",
    "    # Check a few files to see if they're properly formatted\n",
    "    if len(track1_train_files) > 0:\n",
    "        sample = np.load(track1_train_files[0])\n",
    "        print(f\"\\nSample Training File Shape: {sample.shape}\")\n",
    "        print(f\"Channels: RGB + Instance Mask + Type Mask\")\n",
    "        print(f\"  - RGB shape: {sample[..., :3].shape}\")\n",
    "        print(f\"  - Instance mask shape: {sample[..., 3].shape}\")\n",
    "        print(f\"  - Type mask shape: {sample[..., 4].shape}\")\n",
    "        \n",
    "        # Print some statistics\n",
    "        print(f\"\\nInstance mask unique values: {np.unique(sample[..., 3])}\")\n",
    "        print(f\"Type mask unique values: {np.unique(sample[..., 4])}\")\n",
    "\n",
    "# Check if our processed data is ready\n",
    "check_processed_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fc625",
   "metadata": {},
   "source": [
    "### Run Training\n",
    "\n",
    "Now we'll set up the code to run HoVer-Net training using our custom configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c4927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting HoVer-Net training for PUMA Track 1...\n",
      "Using GPUs: 0\n",
      "\n",
      "Command: python ./hover_net/run_train.py --gpu=0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/docopt.py:165: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  name = re.findall('(<\\S*?>)', source)[0]\n",
      "/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/docopt.py:166: SyntaxWarning: invalid escape sequence '\\['\n",
      "  value = re.findall('\\[default: (.*)\\]', source, flags=re.I)\n",
      "/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/docopt.py:207: SyntaxWarning: invalid escape sequence '\\['\n",
      "  matched = re.findall('\\[default: (.*)\\]', description, flags=re.I)\n",
      "/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/docopt.py:456: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  split = re.split('\\n *(<\\S+?>|-\\S+?)', doc)[1:]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/alix_anneraud/Git/INSA/Deep_learning_project/code/./hover_net/run_train.py\", line 37, in <module>\n",
      "    from dataloader.train_loader import FileLoader\n",
      "  File \"/home/alix_anneraud/Git/INSA/Deep_learning_project/code/hover_net/dataloader/train_loader.py\", line 12, in <module>\n",
      "    import imgaug as ia\n",
      "  File \"/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/imgaug/__init__.py\", line 7, in <module>\n",
      "    from imgaug.imgaug import *  # pylint: disable=redefined-builtin\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/imgaug/imgaug.py\", line 45, in <module>\n",
      "    NP_FLOAT_TYPES = set(np.sctypes[\"float\"])\n",
      "                         ^^^^^^^^^^\n",
      "  File \"/home/alix_anneraud/Git/INSA/Deep_learning_project/code/.venv/lib/python3.12/site-packages/numpy/__init__.py\", line 400, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: `np.sctypes` was removed in the NumPy 2.0 release. Access dtypes explicitly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training failed with error: Command '['python', './hover_net/run_train.py', '--gpu=0']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def train_hovernet(track_id=1, gpu_ids=\"0\"):\n",
    "    \"\"\"Train HoVer-Net for a specific PUMA track.\"\"\"\n",
    "    # Set environment variable for GPUs\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_ids\n",
    "    \n",
    "    # Command to run the training script\n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        f\"./hover_net/run_train.py\", \n",
    "        f\"--gpu={gpu_ids}\"\n",
    "    ]\n",
    "    \n",
    "    # Make sure the config file is properly imported\n",
    "    original_config_path = \"./hover_net/config.py\"\n",
    "    custom_config_path = f\"./hover_net/puma_track{track_id}_config.py\"\n",
    "    \n",
    "    # Backup original config\n",
    "    if os.path.exists(original_config_path):\n",
    "        with open(original_config_path, \"r\") as f:\n",
    "            original_config_content = f.read()\n",
    "        \n",
    "        # Create backup\n",
    "        with open(original_config_path + \".backup\", \"w\") as f:\n",
    "            f.write(original_config_content)\n",
    "    \n",
    "    # Copy our custom config to the main config.py file\n",
    "    with open(custom_config_path, \"r\") as f:\n",
    "        custom_config_content = f.read()\n",
    "    \n",
    "    with open(original_config_path, \"w\") as f:\n",
    "        f.write(custom_config_content)\n",
    "    \n",
    "    print(f\"Starting HoVer-Net training for PUMA Track {track_id}...\")\n",
    "    print(f\"Using GPUs: {gpu_ids}\")\n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the training script\n",
    "        # In a real execution, you would uncomment the following:\n",
    "        result = subprocess.run(cmd, check=True)\n",
    "        print(f\"Training completed with exit code {result.returncode}\")\n",
    "        print(\"[Simulated] Training would start here. In a real execution, uncomment the subprocess.run call.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Training failed with error: {e}\")\n",
    "    finally:\n",
    "        # Restore original config if backup exists\n",
    "        if os.path.exists(original_config_path + \".backup\"):\n",
    "            with open(original_config_path + \".backup\", \"r\") as f:\n",
    "                backup_content = f.read()\n",
    "            \n",
    "            with open(original_config_path, \"w\") as f:\n",
    "                f.write(backup_content)\n",
    "            \n",
    "            # Remove backup\n",
    "            os.remove(original_config_path + \".backup\")\n",
    "\n",
    "# Train for Track 1 (uncomment to run)\n",
    "train_hovernet(track_id=1, gpu_ids=\"0\")\n",
    "\n",
    "# Train for Track 2 (uncomment to run)\n",
    "# train_hovernet(track_id=2, gpu_ids=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8ba083",
   "metadata": {},
   "source": [
    "### Monitor Training Progress\n",
    "\n",
    "After starting the training, we can monitor its progress through TensorBoard logs. HoVer-Net training saves logs in the specified log directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63130ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Start TensorBoard (uncomment to run)\n",
    "# %tensorboard --logdir=logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff7f6a0",
   "metadata": {},
   "source": [
    "## 6. Inference with Trained Models\n",
    "\n",
    "After training, we can use the trained models to make predictions on new images. HoVer-Net provides a script for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(track_id=1, gpu_ids=\"0\"):\n",
    "    \"\"\"Run inference using a trained HoVer-Net model.\"\"\"\n",
    "    # Path to the trained model checkpoint\n",
    "    checkpoint_path = f\"./logs/puma_track{track_id}/hovernet_epoch=50.tar\"\n",
    "    \n",
    "    # Path to test images\n",
    "    test_dir = f\"./test_images\"\n",
    "    output_dir = f\"./results/track{track_id}\"\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    nr_types = 4 if track_id == 1 else 11\n",
    "    \n",
    "    # Command to run inference\n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        \"./hover_net/run_infer.py\",\n",
    "        \"tile\",\n",
    "        f\"--gpu={gpu_ids}\",\n",
    "        f\"--nr_types={nr_types}\",\n",
    "        f\"--model_path={checkpoint_path}\",\n",
    "        \"--model_mode=original\",\n",
    "        f\"--input_dir={test_dir}\",\n",
    "        f\"--output_dir={output_dir}\",\n",
    "        \"--save_qupath\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Running inference with PUMA Track {track_id} model...\")\n",
    "    print(f\"Using GPUs: {gpu_ids}\")\n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the inference script\n",
    "        # In a real execution, you would uncomment the following:\n",
    "        # result = subprocess.run(cmd, check=True)\n",
    "        # print(f\"Inference completed with exit code {result.returncode}\")\n",
    "        print(\"[Simulated] Inference would start here. In a real execution, uncomment the subprocess.run call.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Inference failed with error: {e}\")\n",
    "\n",
    "# Run inference with Track 1 model (uncomment to run)\n",
    "# run_inference(track_id=1, gpu_ids=\"0\")\n",
    "\n",
    "# Run inference with Track 2 model (uncomment to run)\n",
    "# run_inference(track_id=2, gpu_ids=\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca0e00",
   "metadata": {},
   "source": [
    "## 7. Evaluate Results\n",
    "\n",
    "Finally, we can evaluate the performance of our trained models on the validation set using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e396c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(track_id=1):\n",
    "    \"\"\"Evaluate the trained model using metrics from HoVer-Net.\"\"\"\n",
    "    # Path to the results directory\n",
    "    results_dir = f\"./results/track{track_id}\"\n",
    "    \n",
    "    # Command to compute metrics\n",
    "    cmd = [\n",
    "        \"python\", \n",
    "        \"./hover_net/compute_stats.py\",\n",
    "        f\"--pred_dir={results_dir}\",\n",
    "        f\"--true_dir=./processed_data/track{track_id}_val\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"Computing metrics for PUMA Track {track_id} model...\")\n",
    "    print(f\"\\nCommand: {' '.join(cmd)}\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Run the metrics computation script\n",
    "        # In a real execution, you would uncomment the following:\n",
    "        # result = subprocess.run(cmd, check=True)\n",
    "        # print(f\"Metrics computation completed with exit code {result.returncode}\")\n",
    "        print(\"[Simulated] Metrics computation would start here. In a real execution, uncomment the subprocess.run call.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Metrics computation failed with error: {e}\")\n",
    "\n",
    "# Evaluate Track 1 model (uncomment to run)\n",
    "# evaluate_model(track_id=1)\n",
    "\n",
    "# Evaluate Track 2 model (uncomment to run)\n",
    "# evaluate_model(track_id=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82997f1e",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the process of training HoVer-Net models for the PUMA challenge tasks. The steps included:\n",
    "\n",
    "1. Exploring and understanding the PUMA dataset\n",
    "2. Converting GeoJSON annotations to the format required by HoVer-Net\n",
    "3. Processing images and generating patches for training\n",
    "4. Creating custom configurations for HoVer-Net\n",
    "5. Training separate models for Track 1 (3 classes) and Track 2 (10 classes)\n",
    "6. Running inference on new images\n",
    "7. Evaluating model performance with metrics\n",
    "\n",
    "HoVer-Net's architecture, with its dedicated branches for segmentation and classification, is well-suited for the PUMA challenge which requires both accurate nuclei segmentation and classification.\n",
    "\n",
    "To improve results, consider the following:\n",
    "- Try different data augmentation techniques\n",
    "- Adjust learning rates and training epochs\n",
    "- Experiment with different model configurations (original vs. fast mode)\n",
    "- Explore ensemble methods by combining predictions from multiple models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
