{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2e6e30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ğŸ”¬ Segmentation panoptique des noyaux et des tissus dans le mÃ©lanome avancÃ© (PUMA)\n",
    "## ğŸ§¬ Projet d'apprentissage profond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723314b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Bonjour Ã  tous,\n",
    "\n",
    "Nous allons vous prÃ©senter notre projet de deep learning sur la segmentation et classification des noyaux cellulaires dans le mÃ©lanome.\n",
    "\n",
    "Dans ce projet, nous avons travaillÃ© sur l'application de mÃ©thodes et modÃ¨les de deep  sur la segmentation et classification des noyaux cellulaires et tissus dans les images histopathologiques du mÃ©lanome en utilisant des techniques de deep learning.\n",
    "\n",
    "Ce projet se base sur le concours PUMA organisÃ© par le consortium de recherche sur le mÃ©lan\n",
    "\n",
    "Nous nous basons sur l'article scientifique : \"PUMA: A dataset for deep learning-based nuclei and tissue segmentation in advanced melanoma with improved biomarker potential\" publiÃ© dans GigaScience en 2024.\n",
    "\n",
    "Ce travail s'inscrit dans une dÃ©marche d'amÃ©lioration des biomarqueurs pronostiques pour le mÃ©lanome avancÃ©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b0b7a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. ğŸ“œ Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a1d22",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ©º Le mÃ©lanome et ses biomarqueurs\n",
    "\n",
    "- MÃ©lanome : cancer agressif de la peau en augmentation\n",
    "- 50% des patients ne rÃ©pondent pas Ã  l'immunothÃ©rapie\n",
    "- Les lymphocytes infiltrant la tumeur (TILs) = biomarqueur pronostique clÃ©\n",
    "- Limites actuelles : Ã©valuation manuelle subjective et variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ae1c2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Le mÃ©lanome est une forme particuliÃ¨rement agressive de cancer cutanÃ© dont l'incidence augmente globalement. Bien que le mÃ©lanome primaire soit souvent traitÃ© par excision chirurgicale, le mÃ©lanome avancÃ© nÃ©cessite une immunothÃ©rapie par inhibiteurs de points de contrÃ´le immunitaires.\n",
    "\n",
    "Malheureusement, environ la moitiÃ© des patients ne rÃ©pondent pas Ã  cette thÃ©rapie, qui est coÃ»teuse et potentiellement toxique. Il est donc crucial d'identifier des biomarqueurs capables de prÃ©dire la rÃ©ponse au traitement.\n",
    "\n",
    "Les lymphocytes infiltrant la tumeur (TILs) sont reconnus comme un biomarqueur pronostique important, mais leur Ã©valuation manuelle est subjective, chronophage et souffre d'une variabilitÃ© inter-observateurs considÃ©rable.\n",
    "\n",
    "Ces limitations motivent le dÃ©veloppement d'approches automatisÃ©es basÃ©es sur l'intelligence artificielle pour quantifier et caractÃ©riser les TILs de maniÃ¨re plus objective et reproductible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573eeb9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ¤” DÃ©fis spÃ©cifiques au mÃ©lanome\n",
    "\n",
    "- Cellules de mÃ©lanome mimÃ©tiques imitant d'autres types cellulaires\n",
    "- ModÃ¨les gÃ©nÃ©riques (HoverNet sur PanNuke) : performance sous-optimale\n",
    "- Confusion frÃ©quente entre cellules tumorales/lymphocytes/stromales\n",
    "\n",
    "â†’ NÃ©cessitÃ© d'un modÃ¨le spÃ©cifique au mÃ©lanome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383ce95",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "L'analyse histopathologique du mÃ©lanome prÃ©sente des dÃ©fis spÃ©cifiques qui compliquent l'application des modÃ¨les d'IA existants :\n",
    "\n",
    "1. Les cellules de mÃ©lanome ont une capacitÃ© unique Ã  imiter morphologiquement d'autres types cellulaires, rendant leur identification automatique particuliÃ¨rement difficile.\n",
    "\n",
    "2. Les modÃ¨les gÃ©nÃ©riques comme HoverNet, mÃªme lorsqu'ils sont prÃ©-entraÃ®nÃ©s sur des datasets comme PanNuke (qui inclut des Ã©chantillons de peau), montrent des performances sous-optimales sur les images de mÃ©lanome.\n",
    "\n",
    "3. Ces modÃ¨les confondent frÃ©quemment les cellules tumorales avec des lymphocytes ou des cellules stromales, compromettant ainsi l'Ã©valuation prÃ©cise des TILs.\n",
    "\n",
    "4. Les mÃ©thodes manuelles actuelles souffrent Ã©galement d'une grande variabilitÃ© dans l'Ã©valuation de la localisation des TILs (intratumorale vs pÃ©ritumorale), qui est pourtant cruciale pour Ã©valuer leur valeur pronostique.\n",
    "\n",
    "Ces dÃ©fis justifient le dÃ©veloppement d'un modÃ¨le spÃ©cifiquement adaptÃ© au mÃ©lanome, entraÃ®nÃ© sur des donnÃ©es annotÃ©es de haute qualitÃ©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816bcb7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ“Š Jeu de donnÃ©es (PUMA)\n",
    "\n",
    "- RÃ©gions tumorales \n",
    "  - 155 mÃ©lanomes primaires\n",
    "  - 155 mÃ©lanomes mÃ©tastatiques\n",
    "  - Images TIFF H&E Ã  40x (1024Ã—1024 pixels)\n",
    "- Annotations de zones en GeoJSON validÃ©es par un dermato-pathologiste :\n",
    "  - Noyaux :\n",
    "    - Zone : polygone\n",
    "    - Classe : tumeur, lymphocytes, plasmocytes ... (10 classes)\n",
    "  - Tissus : tumeur, stroma, Ã©piderme, vaisseaux sanguins ... (5 classes)\n",
    "    - Zone : polygone(s)\n",
    "    - Classe : tumeur, Ã©piderme, vaisseaux sanguins ... (5 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3bc267",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Le dataset PUMA (Panoptic segmentation of nUclei and tissue in MelanomA) constitue la premiÃ¨re base de donnÃ©es spÃ©cifique au mÃ©lanome pour la segmentation panoptique des noyaux cellulaires et des tissus :\n",
    "\n",
    "- Il comprend 155 rÃ©gions d'intÃ©rÃªt (ROIs) de mÃ©lanomes primaires et 155 de mÃ©lanomes mÃ©tastatiques, offrant ainsi un Ã©chantillonnage reprÃ©sentatif de la diversitÃ© morphologique de cette pathologie.\n",
    "\n",
    "- Les images sont des coupes histologiques colorÃ©es Ã  l'hÃ©matoxyline et Ã  l'Ã©osine (H&E), numÃ©risÃ©es Ã  un grossissement de 40x avec une rÃ©solution de 1024Ã—1024 pixels.\n",
    "\n",
    "- Chaque ROI est accompagnÃ©e d'une ROI contextuelle de 5120Ã—5120 pixels centrÃ©e autour d'elle, permettant d'analyser l'environnement tissulaire plus large.\n",
    "\n",
    "- Les annotations des noyaux cellulaires identifient 10 types distincts : tumeur, lymphocytes, plasmocytes, histiocytes, mÃ©lanophages, neutrophiles, cellules stromales, Ã©pithÃ©lium, endothÃ©lium et cellules apoptotiques.\n",
    "\n",
    "- Les annotations tissulaires comprennent 5 catÃ©gories : tumeur, stroma, Ã©pithÃ©lium, vaisseaux sanguins et zones nÃ©crotiques.\n",
    "\n",
    "- Toutes les annotations ont Ã©tÃ© rÃ©alisÃ©es par un professionnel mÃ©dical et vÃ©rifiÃ©es par un dermato-pathologiste certifiÃ©, garantissant leur qualitÃ© et leur pertinence clinique.\n",
    "\n",
    "Ce jeu de donnÃ©es unique permet de dÃ©velopper et d'Ã©valuer des modÃ¨les spÃ©cifiques au mÃ©lanome avec un niveau de granularitÃ© sans prÃ©cÃ©dent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b8dbc0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ–¼ï¸ Jeu de donnÃ©es (PUMA)\n",
    "\n",
    "![./images/6f3736bd-a0f5-42a7-8d54-98852b7e6af1.png](./images/6f3736bd-a0f5-42a7-8d54-98852b7e6af1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c04361",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ¯ Principe\n",
    "\n",
    "Il y a 2 tÃ¢ches : \n",
    "\n",
    "1. Noyaux cellulaires\n",
    "   1. Segmentation\n",
    "   2. Classification (10 classes)\n",
    "2. Segmentation des tissus\n",
    "   1. Segmentation\n",
    "   2. Classification (5 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a93ef9",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Pour permettre le diagnostic et le pronostic du mÃ©lanome, il est essentiel de segmenter et classifier les noyaux cellulaires et les tissus dans les images histopathologiques.\n",
    "\n",
    "Il s'agit de deux tÃ¢ches de segmentation panoptique, oÃ¹ chaque pixel d'une image est classÃ© en fonction de son appartenance Ã  une catÃ©gorie spÃ©cifique.\n",
    "\n",
    "Attention, il faut bien faire la diffÃ©rence entre la segmentation panoptique et la segmentation sÃ©mantique. \n",
    "\n",
    "La segmentation panoptique consiste Ã  segmenter chaque pixel d'une image en lui attribuant une Ã©tiquette de classe, tout en tenant compte de la hiÃ©rarchie des objets prÃ©sents dans l'image. En revanche, la segmentation sÃ©mantique se concentre uniquement sur l'attribution d'Ã©tiquettes de classe aux pixels, sans tenir compte de la hiÃ©rarchie ou des relations entre les objets.\n",
    "\n",
    "Ainsi, il Ã  la fois une tÃ¢che de segmentation sÃ©mantique (identifier les classes) et une tÃ¢che de dÃ©tection d'objets (identifier les instances).\n",
    "\n",
    "Il faut donc 2 modÃ¨les : un pour la segmentation des noyaux et un pour la segmentation des tissus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1b68e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. ğŸ› ï¸ MÃ©thodologie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191ae50",
   "metadata": {},
   "source": [
    "1. Ã‰tat de l'art \n",
    "2. PrÃ©traitement\n",
    "3. EntraÃ®nement\n",
    "4. Ã‰valuation\n",
    "5. InterprÃ©tation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e40da",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "La mÃ©thodologie de ce projet se dÃ©cline en plusieurs Ã©tapes clÃ©s :\n",
    "\n",
    "1. **Ã‰tat de l'art** : Analyse des mÃ©thodes existantes pour la segmentation et la classification des noyaux cellulaires et des tissus dans les images histopathologiques, en mettant l'accent sur les dÃ©fis spÃ©cifiques au mÃ©lanome. Cette Ã©tape est rÃ©alisÃ©e en consultant la littÃ©rature scientifique et Ã©galement en demandant Ã  ChatGPT de faire une revue de la littÃ©rature sur le sujet.\n",
    "2. **PrÃ©traitement** : PrÃ©paration des donnÃ©es, y compris la normalisation des images, l'augmentation des donnÃ©es et la crÃ©ation de masques d'annotation pour les noyaux et les tissus.\n",
    "3. **EntraÃ®nement** : EntraÃ®nement du modÃ¨le sur le jeu de donnÃ©es PUMA, en utilisant des techniques d'optimisation et de rÃ©gularisation pour amÃ©liorer la performance.\n",
    "4. **Ã‰valuation** : Ã‰valuation des performances du modÃ¨le sur un ensemble de test indÃ©pendant, en utilisant des mÃ©triques appropriÃ©es pour la segmentation et la classification.\n",
    "5. **InterprÃ©tation** : Analyse des rÃ©sultats obtenus, identification des forces et des faiblesses du modÃ¨le, et discussion des implications cliniques potentielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fad9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. ğŸ’» Projet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ad6f0",
   "metadata": {},
   "source": [
    "Nous avons essayÃ© les modÃ¨les suivants :\n",
    "- Segmentation et classification des noyaux :\n",
    "  - CellVit++\n",
    "- Segmentation et classification des tissus :\n",
    "  - HoVer-Net\n",
    "  - nnU-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f29709",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸŒ HoVer-Net\n",
    "\n",
    "Architecture multi-branche :\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    EntrÃ©e[ğŸ“¥ EntrÃ©e] -->|ğŸ–¼ï¸ Image| B[\"ğŸ§  Encodeur (Ex: ResNet50)\"]\n",
    "    B -->|ğŸ”¢ Vecteur| C1[ğŸ”² Segmentation binaire]\n",
    "    B -->|ğŸ”¢ Vecteur| C2[\"â†”ï¸ Cartes HoVer (H & V)\"]\n",
    "    B -->|ğŸ”¢ Vecteur| C3[ğŸ·ï¸ Classification des noyaux]\n",
    "\n",
    "    C1 --> D1[ğŸŸ£ Carte de segmentation]\n",
    "    C2 --> D2[\"ğŸ”µ Carte horizontale (H)\"]\n",
    "    C2 --> D3[\"ğŸŸ¢ Carte verticale (V)\"]\n",
    "    C3 --> D4[ğŸŸ¡ Carte de classification]\n",
    "\n",
    "    D1 & D2 & D3 --> E[ğŸ§© Identifier les instances de noyaux]\n",
    "    D4 & E -->|Noyaux segmentÃ©s et classifiÃ©s| Sortie[ğŸ“¤ Sortie]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78aa0b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## âœ¨ CellVit++\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    EntrÃ©e[ğŸ“¥ EntrÃ©e] -->|ğŸ“· Image| Transformer[ğŸ§  Vision Transformer ]\n",
    "    Transformer -->|ğŸ”¢ Vecteur| Classifieur[ğŸ¯ Classifieur lÃ©ger]\n",
    "    Classifieur -->|Segmentation + classification| Sortie[ğŸ“¤ Sortie]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07210509",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## âœ¨ CellVit++\n",
    "\n",
    "Avantanges : \n",
    "\n",
    "- âš¡ AdaptabilitÃ© : on ne rÃ©entraÃ®ne que le classifieur (pas le modÃ¨le entier)\n",
    "- ğŸ§ª GÃ©nÃ©ration automatique dâ€™un dataset via images IF (CD3, CD20, etc.) + CellViT++\n",
    "- Performance EDLA sur 7 jeux de donnÃ©es, mÃªme en **zero-shot**\n",
    "- Comparable aux mÃ©thodes lourdes (HoVer-Net, SoftCTM)\n",
    "- Jusqu'Ã  **90 % de temps de calcul en moins**\n",
    "- Classifieur entraÃ®nÃ© en **< 2 min**\n",
    "- ğŸ–¥ï¸ Interface web interactive (annotation, AutoML)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c9d82",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "\n",
    "1. **Architecture de base**  \n",
    "   - **Encodeur** : un Vision Transformer prÃ©-entraÃ®nÃ© (â€œfoundation modelâ€ comme HIPT256, UNI, Virchow, SAM-H) qui extrait des Â« tokens Â» (vecteurs dâ€™embedding) correspondant Ã  des rÃ©gions locales de lâ€™image.  \n",
    "   - **TÃªte de segmentation** : gÃ©nÃ¨re directement un masque instance-par-instance pour chaque noyau/cellule, en parallÃ¨le de lâ€™extraction des embeddings, sans coÃ»t computationnel supplÃ©mentaire .\n",
    "\n",
    "2. **Extraction et utilisation des embeddings**  \n",
    "   - Ã€ chaque position oÃ¹ une cellule est dÃ©tectÃ©e, on rÃ©cupÃ¨re le token du dernier bloc du Transformer (Â« cell embedding Â»).  \n",
    "   - Ces embeddings, riches en information morphologique et texturale, servent de **base pour la classification** des cellules, sans avoir Ã  recouper ou recadrer manuellement chaque cellule.\n",
    "\n",
    "3. **Module de classification lÃ©ger et adaptatif**  \n",
    "   - **Structure** : un petit rÃ©seau (une couche cachÃ©e + activation ReLU) prend en entrÃ©e les embeddings et prÃ©dit le type cellulaire (ex : lymphocyte, Ã©pithÃ©liale, mitotique, etc.).  \n",
    "   - **Avantage** : pour un nouveau jeu de classes, seule cette tÃªte de classification est rÃ©entraÃ®nÃ©e sur un petit jeu de donnÃ©es (quelques centaines Ã  milliers dâ€™exemples), laissant lâ€™encodeur et la tÃªte de segmentation inchangÃ©s.  \n",
    "   - **BÃ©nÃ©fices** :  \n",
    "     - **ZÃ©ro-shot** sur nouveaux types de cellules (trÃ¨s bonne segmentation dâ€™emblÃ©e).  \n",
    "     - **Training light** : quelques minutes, faible empreinte carbone.  \n",
    "     - **Haute data-efficience** : performances SOTA mÃªme avec 5â€“25 % des donnÃ©es classiques .\n",
    "\n",
    "4. **Workflow et outils associÃ©s**  \n",
    "   - **GÃ©nÃ©ration automatique de jeux de donnÃ©es** via couplage H&E + immunofluorescence (IF) :  \n",
    "     - Enregistrer un masque binaire IF pour cibler une population cellulaire (ex : CD3 pour lymphocytes).  \n",
    "     - Aligner (registration) H&E â†” IF, segmenter avec CellViT++, puis transfÃ©rer les labels.  \n",
    "     - Permet de crÃ©er de larges jeux de donnÃ©es sans annotation manuelle coÃ»teuse .  \n",
    "   - **Interface web** pour visualisation, annotation et rÃ©entraÃ®nement â€œin the loopâ€ avec un module AutoML intÃ©grÃ©, accessible sans infra HPC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62162eee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Sweep Run\n",
    "\n",
    "![./images/sweep.png](./images/sweep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb82d7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Avant d'entraÃ®ner le modÃ¨le final, on a utilisÃ©Â **Weights & Biases Sweep**Â pour explorer automatiquement diffÃ©rentes combinaisons dâ€™hyperparamÃ¨tres. Cette Ã©tape est cruciale pour identifier les rÃ©glages les plus performants sans avoir Ã  les tester manuellement un par un.\n",
    "\n",
    "Le sweep a permis de tester plusieurs valeurs pour des paramÃ¨tres comme le taux dâ€™apprentissage, la taille du batch, les coefficients de rÃ©gularisation, ou encore les paramÃ¨tres spÃ©cifiques Ã  lâ€™optimiseur. Chaque configuration a Ã©tÃ© Ã©valuÃ©e selon des mÃ©triques de validation (AUROC, F1-Score, etc.), et Wandb a automatiquement sÃ©lectionnÃ© les runs les plus prometteurs.\n",
    "\n",
    "GrÃ¢ce Ã  ce processus, jâ€™ai puÂ **trouver une combinaison dâ€™hyperparamÃ¨tres optimale**, qui a ensuite Ã©tÃ© utilisÃ©e pour entraÃ®ner le modÃ¨le final, dont les performances sont prÃ©sentÃ©es dans les graphiques prÃ©cÃ©dents. Cela garantit une meilleure efficacitÃ© dâ€™apprentissage et une gÃ©nÃ©ralisation plus robuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30596925",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### HyperparamÃ¨tres\n",
    "\n",
    "![./images/resultats_sweep.png](./images/resultats_sweep.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae6887",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Sur cette slide, nous analysons les performances de notre modÃ¨le Ã  travers un sweep dâ€™hyperparamÃ¨tres, avec comme mÃ©trique principale lâ€™AUROC sur le jeu de validation.\n",
    "- **Graphique en haut Ã  gauche** : Ã‰volution de lâ€™AUROC au fil du temps. On observe une progression globale, avec une stabilisation autour de **0.930 Ã  0.934**, ce qui indique une convergence vers des combinaisons efficaces.\n",
    "- **Encart Ã  droite** : Importance des hyperparamÃ¨tres par rapport Ã  lâ€™AUROC. Les plus influents sont :\n",
    "    - model.hidden_dim (taille des couches cachÃ©es),\n",
    "    - training.optimizer.lr (taux dâ€™apprentissage),\n",
    "    - training.drop_rate (taux de dropout).\n",
    "        \n",
    "On note une **corrÃ©lation positive du hidden_dim** et du **dropout**, et une **corrÃ©lation nÃ©gative pour le learning_rate**, indiquant quâ€™un taux trop Ã©levÃ© dÃ©grade la performance.\n",
    "        \n",
    "- **Graphique en bas** : Visualisation parallÃ¨le des hyperparamÃ¨tres. Chaque ligne correspond Ã  un essai, colorÃ©e selon la valeur de lâ€™AUROC.\n",
    "    - Les lignes les plus claires (meilleurs scores) se regroupent autour de certaines plages :\n",
    "        - hidden_dim autour de 300-450,\n",
    "        - drop_rate entre 0.2 et 0.4,\n",
    "        - learning_rate entre 2e-5 et 5e-5.\n",
    "\n",
    "**Le sweep a permis dâ€™identifier une configuration optimale et de mieux comprendre lâ€™influence de chaque paramÃ¨tre sur la performance du modÃ¨le.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb564ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸš€ nnU-Net\n",
    "\n",
    "- MÃªme structure que U-Net classique.\n",
    "- Ajustements minimes :  \n",
    "  - **Leaky ReLU** Ã  la place du **ReLU**  \n",
    "  - Instance Normalization au lieu de BatchNorm  \n",
    "- Tout se joue dans le **pipeline automatique** :  \n",
    "  - prÃ©-traitement,  \n",
    "  - entraÃ®nement,  \n",
    "  - infÃ©rence,  \n",
    "  - post-traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef30b706",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸš€ U-Net\n",
    "\n",
    "1. **Chemin de contraction**\n",
    "   - SÃ©ries de blocs : (Conv 3Ã—3 â†’ ReLU) Ã—2 â†’ MaxPool 2Ã—2  \n",
    "   - Ã€ chaque pooling, on double le nombre de canaux.  \n",
    "2. **Chemin d'expansion**\n",
    "   - Up-convolution 2Ã—2 (halving des canaux)  \n",
    "   - **Skip connection** : concatÃ¨ne la carte de la couche correspondante du contratant  \n",
    "   - (Conv 3Ã—3 â†’ ReLU) Ã—2  \n",
    "3. **Sortie**  \n",
    "   - Conv 1Ã—1 : Carte de segmentation pixel-wise  \n",
    "4. **Tiling & overlap-tile strategy** pour traiter de grandes images\n",
    "\n",
    "Le U-Net capture Ã  la fois le contexte global (contracting) et la localisation fine (expansive).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de764513",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸš€ nnU-Net\n",
    "\n",
    "Avantages :\n",
    "\n",
    "âœ… nnU-Net = pipeline automatique, pas de nouvelle architecture  \n",
    "âœ… GÃ©nÃ©ralise trÃ¨s bien Ã  des cas variÃ©s  \n",
    "âœ… Montre que le **contexte d'entraÃ®nement** est souvent plus critique que lâ€™architecture elle-mÃªme\n",
    "\n",
    "ğŸ§ª IdÃ©al pour benchmark, prÃ©-entraÃ®nement, ou compÃ©tition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38a564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. ğŸ“ˆ RÃ©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490d55d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## âœ¨ CellVit++\n",
    "\n",
    "![./images/best_run.png](./images/best_run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77838b5",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Voici lâ€™Ã©volution des principales mÃ©triques pour notre modÃ¨le CellViT-SAM-H sur 50 Ã©tapes d'entraÃ®nement. On observe dâ€™abord une baisse rÃ©guliÃ¨re de la perte d'entraÃ®nement, signe que le modÃ¨le apprend efficacement Ã  partir des donnÃ©es.\n",
    "\n",
    "Du cÃ´tÃ© de la validation, la perte diminue nettement au dÃ©but puis se stabilise, avec une lÃ©gÃ¨re hausse aprÃ¨s lâ€™Ã©tape 10, ce qui indique un dÃ©but de surapprentissage. MalgrÃ© cela, les mÃ©triques de performance restent trÃ¨s solides : lâ€™AUROC dÃ©passe 0.93, ce qui montre une trÃ¨s bonne capacitÃ© Ã  distinguer les classes. Le F1-Score se stabilise autour de 0.767, ce qui traduit un bon Ã©quilibre entre prÃ©cision et rappel. Enfin, la prÃ©cision moyenne (Average Precision) progresse rapidement avant de se stabiliser autour de 0.445, ce qui reste un trÃ¨s bon score pour ce type de tÃ¢che.\n",
    "\n",
    "En rÃ©sumÃ©, le modÃ¨le montre une excellente capacitÃ© dâ€™apprentissage et de gÃ©nÃ©ralisation, avec un lÃ©ger surapprentissage Ã  surveiller. Un arrÃªt anticipÃ© de l'entraÃ®nement autour de lâ€™Ã©tape 15 Ã  20 pourrait permettre dâ€™optimiser encore davantage la performance sur donnÃ©es de validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a18d4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸŒ HoVer-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296a785",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸš€ nnU-Net\n",
    "\n",
    "Impossible de lancer un apprentissage : \n",
    "  - Environnement incompatible ?\n",
    "  - DÃ©pendances ?\n",
    "\n",
    "DÃ©pannage compliquÃ© car aucun message d'erreur (processus bloquÃ©).\n",
    "\n",
    "```sh\n",
    "Date: Tue Apr 29 12:41:03 PM CEST 2025\n",
    "Noeud: juliet4\n",
    "Job ID: 22392\n",
    "Partition: mesonet\n",
    "Compte: m25031\n",
    "GPUs allouÃ©s: 0\n",
    "nnUNet_preprocessed set to: /home/alanneraud/Deep_learning_project/nnunet/nnUNet_preprocessed\n",
    "nnUNet_raw set to: /home/alanneraud/Deep_learning_project/nnunet/nnUNet_raw\n",
    "nnUNet_results set to: /home/alanneraud/Deep_learning_project/nnunet/nnUNet_results\n",
    "Activation de l'environnement uv: /home/alanneraud/Deep_learning_project/nnunet/.venv\n",
    "Python 3.10.17\n",
    "PyTorch et nnUNet (avec trainer custom) sont supposÃ©s Ãªtre installÃ©s dans l'environnement uv.\n",
    "VÃ©rification de la disponibilitÃ© du GPU via PyTorch...\n",
    "PyTorch version: 2.7.0+cu126\n",
    "CUDA available: True\n",
    "Device count: 1\n",
    "Current device: 0\n",
    "Device name: NVIDIA A100-SXM4-80GB\n",
    "Fin de la vÃ©rification PyTorch GPU.\n",
    "Ã‰tape 5: Lancement du prÃ©-entraÃ®nement (Task 2 - NSCLC) avec nnUNetTrainerIgnoreIndex et plans nnUNetPlans_pretrain...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7115dc7",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Concernant lâ€™entraÃ®nement de nnU-Net, il nous a Ã©tÃ© impossible de lancer un entraÃ®nement car il se mettait Ã  freeze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb74dc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. âœ… Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfd1b6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸ¤” Critique\n",
    "\n",
    "- **Occupation des nÅ“uds :**\n",
    "  - Queue d'attente importante\n",
    "  - Plantage partiel de `juliet2` et `juliet4`\n",
    "- **QualitÃ© de l'implÃ©mentation des modÃ¨les :**\n",
    "  - Gestion insuffisante des erreurs.\n",
    "  - Manque de clartÃ© et de robustesse du code.\n",
    "- **StabilitÃ© et dÃ©pendances des modÃ¨les :**\n",
    "  - DifficultÃ©s liÃ©es Ã  la gestion des versions des librairies.\n",
    "  - InstabilitÃ© potentielle des environnements d'exÃ©cution.\n",
    "- **Maintenance et support des modÃ¨les :**\n",
    "  - Peu de suivi des problÃ¨mes signalÃ©s (issues).\n",
    "  - Manque de rÃ©activitÃ© sur les contributions (pull requests)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36add7c4",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Au cours de ce projet, l'exploitation des modÃ¨les existants a prÃ©sentÃ© plusieurs dÃ©fis.\n",
    "\n",
    "1. la gestion des ressources informatiques a Ã©tÃ© problÃ©matique. La queue d'attente pour accÃ©der aux nÅ“uds de calcul Ã©tait souvent longue, ce qui a entraÃ®nÃ© des retards dans le dÃ©marrage des expÃ©riences. De plus, le nÅ“ud `juliet2` a rencontrÃ© des problÃ¨mes de stabilitÃ©, il Ã©tait impossible d'utiliser les ressources graphiques sur ce dernier, tandis que le nÅ“ud `juliet4` a Ã©tÃ© partiellement bloquÃ© par une tÃ¢che qui ne se termine jamais.\n",
    "\n",
    "2. La qualitÃ© de l'implÃ©mentation de certains outils s'est avÃ©rÃ©e perfectible. Par exemple, une gestion limitÃ©e des exceptions a entraÃ®nÃ© des arrÃªts inattendus du programme, parfois sans message d'erreur explicite, compliquant le dÃ©bogage.\n",
    "\n",
    "3. La stabilitÃ© des modÃ¨les a Ã©tÃ© affectÃ©e par une gestion imprÃ©cise des dÃ©pendances. Il a fallu tester itÃ©rativement diffÃ©rentes versions de librairies pour assurer la compatibilitÃ© et le bon fonctionnement, ce qui a ralenti le processus de dÃ©veloppement.\n",
    "\n",
    "4. Le manque de maintenance active et de support communautaire pour certains des outils utilisÃ©s a Ã©tÃ© un frein. Les problÃ¨mes signalÃ©s par la communautÃ© (issues GitHub) restent souvent sans rÃ©ponse, et les propositions d'amÃ©lioration (pull requests) ne sont pas intÃ©grÃ©es, ce qui soulÃ¨ve des questions sur la pÃ©rennitÃ© et la fiabilitÃ© Ã  long terme de ces outils."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ff22e3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ğŸŒ Impact\n",
    "\n",
    "- **Environnemental :**\n",
    "  - Fabrication des puces\n",
    "  - Consommation Ã©nergÃ©tique\n",
    "\n",
    "- **Politique :** \n",
    "  - IndÃ©pendance sur la fabrication des machines de lithographie \n",
    "  - DÃ©pendance Ã  l'Ã©gard de TaÃ¯wan (TSMC) pour la fabrication des puces\n",
    "  - DÃ©pendance Ã  l'Ã©gard de la Chine pour les terres rares\n",
    "  - DÃ©pendance Ã  l'Ã©gard des Ã‰tats-Unis pour les logiciels et les licences (ROCm et CUDA)\n",
    "\n",
    "- **SociÃ©tal :**\n",
    "  - AmÃ©lioration du diagnostic/pronostic\n",
    "  - Optimisation du flux de travail\n",
    "  - Aide Ã  la dÃ©cision thÃ©rapeutique\n",
    "  - Potentiel de rÃ©duction des coÃ»ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57807bd1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Enfin, abordons l'impact de ce type de projet et des technologies sous-jacentes.\n",
    "\n",
    "Sur le plan **environnemental**, \n",
    "1. il faut considÃ©rer l'empreinte liÃ©e Ã  la fabrication des puces Ã©lectroniques. Cela inclut l'extraction et la purification de grandes quantitÃ©s de silicium, issu du sable, pour crÃ©er les *wafers* sur lesquels sont gravÃ©es les puces mÃ©moire (VRAM) et les processeurs graphiques (GPU). La fabrication des GPU est particuliÃ¨rement gourmande : leurs *dies* (les puces individuelles) sont trÃ¨s larges, ce qui augmente le taux de perte lors de la dÃ©coupe des *wafers*.\n",
    "2. Ã€ cela s'ajoute la consommation Ã©nergÃ©tique significative des usines de fabrication (*fabs*), des centres de donnÃ©es et des phases d'entraÃ®nement des modÃ¨les.\n",
    "\n",
    "D'un point de vue **politique et Ã©conomique**, observons une forte dÃ©pendance gÃ©ostratÃ©gique.\n",
    "1. La production des puces de pointe est concentrÃ©e Ã  TaÃ¯wan avec TSMC.\n",
    "2. L'approvisionnement en terres rares, essentielles, dÃ©pend largement de la Chine.\n",
    "3. Les logiciels et Ã©cosystÃ¨mes comme CUDA ou ROCm sont majoritairement amÃ©ricains.\n",
    "4. Cependant, l'Europe dÃ©tient un avantage stratÃ©gique majeur avec l'entreprise nÃ©erlandaise ASML, qui produit les machines de lithographie EUV (Extreme Ultraviolet) indispensables Ã  la gravure des semi-conducteurs les plus avancÃ©s et utilisÃ©es par tous les grands fondeurs mondiaux.\n",
    "\n",
    "Cependant, l'impact le plus direct et positif se situe au niveau **clinique et sociÃ©tal**.\n",
    "1. Ces outils ont le potentiel d'amÃ©liorer significativement la prÃ©cision et la reproductibilitÃ© du diagnostic et du pronostic du mÃ©lanome.\n",
    "2. Ils peuvent optimiser le flux de travail des pathologistes, leur permettant de se concentrer sur les cas les plus complexes.\n",
    "3. En fournissant une analyse plus fine, ils constituent une aide prÃ©cieuse Ã  la dÃ©cision thÃ©rapeutique, notamment pour prÃ©dire la rÃ©ponse Ã  l'immunothÃ©rapie.\n",
    "4. Ã€ terme, cela pourrait mÃªme contribuer Ã  une rÃ©duction des coÃ»ts de santÃ© en Ã©vitant des traitements inefficaces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (diaporama)",
   "language": "python",
   "name": "diaporama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
