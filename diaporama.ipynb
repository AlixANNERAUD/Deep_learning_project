{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b2e6e30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Segmentation et Classification des Noyaux Cellulaires dans le Mélanome\n",
    "## Projet Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723314b",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Dans ce projet, nous étudions la segmentation et classification des noyaux cellulaires dans les images histopathologiques du mélanome en utilisant des techniques de deep learning.\n",
    "\n",
    "Nous nous basons sur l'article scientifique : \"PUMA: A dataset for deep learning-based nuclei and tissue segmentation in advanced melanoma with improved biomarker potential\" publié dans GigaScience en 2024.\n",
    "\n",
    "Ce travail s'inscrit dans une démarche d'amélioration des biomarqueurs pronostiques pour le mélanome avancé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679a1d22",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contexte : Le Mélanome et ses Biomarqueurs\n",
    "\n",
    "- Mélanome : cancer agressif de la peau en augmentation\n",
    "- 50% des patients ne répondent pas à l'immunothérapie\n",
    "- Les lymphocytes infiltrant la tumeur (TILs) = biomarqueur pronostique clé\n",
    "- Limites actuelles : évaluation manuelle subjective et variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ae1c2",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Le mélanome est une forme particulièrement agressive de cancer cutané dont l'incidence augmente globalement. Bien que le mélanome primaire soit souvent traité par excision chirurgicale, le mélanome avancé nécessite une immunothérapie par inhibiteurs de points de contrôle immunitaires.\n",
    "\n",
    "Malheureusement, environ la moitié des patients ne répondent pas à cette thérapie, qui est coûteuse et potentiellement toxique. Il est donc crucial d'identifier des biomarqueurs capables de prédire la réponse au traitement.\n",
    "\n",
    "Les lymphocytes infiltrant la tumeur (TILs) sont reconnus comme un biomarqueur pronostique important, mais leur évaluation manuelle est subjective, chronophage et souffre d'une variabilité inter-observateurs considérable.\n",
    "\n",
    "Ces limitations motivent le développement d'approches automatisées basées sur l'intelligence artificielle pour quantifier et caractériser les TILs de manière plus objective et reproductible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1573eeb9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Défis Spécifiques au Mélanome\n",
    "\n",
    "- Cellules de mélanome mimétiques imitant d'autres types cellulaires\n",
    "- Modèles génériques (HoverNet sur PanNuke) : performance sous-optimale\n",
    "- Confusion fréquente entre cellules tumorales/lymphocytes/stromales\n",
    "\n",
    "→ Nécessité d'un modèle spécifique au mélanome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383ce95",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "L'analyse histopathologique du mélanome présente des défis spécifiques qui compliquent l'application des modèles d'IA existants :\n",
    "\n",
    "1. Les cellules de mélanome ont une capacité unique à imiter morphologiquement d'autres types cellulaires, rendant leur identification automatique particulièrement difficile.\n",
    "\n",
    "2. Les modèles génériques comme HoverNet, même lorsqu'ils sont pré-entraînés sur des datasets comme PanNuke (qui inclut des échantillons de peau), montrent des performances sous-optimales sur les images de mélanome.\n",
    "\n",
    "3. Ces modèles confondent fréquemment les cellules tumorales avec des lymphocytes ou des cellules stromales, compromettant ainsi l'évaluation précise des TILs.\n",
    "\n",
    "4. Les méthodes manuelles actuelles souffrent également d'une grande variabilité dans l'évaluation de la localisation des TILs (intratumorale vs péritumorale), qui est pourtant cruciale pour évaluer leur valeur pronostique.\n",
    "\n",
    "Ces défis justifient le développement d'un modèle spécifiquement adapté au mélanome, entraîné sur des données annotées de haute qualité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816bcb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Le Jeu de Données PUMA\n",
    "\n",
    "- 155 ROIs de mélanomes primaires + 155 ROIs métastatiques\n",
    "- Images H&E à 40x (1024×1024 pixels)\n",
    "- Annotations validées par un dermato-pathologiste\n",
    "- Noyaux : tumeur, lymphocytes, plasmocytes, histiocytes...\n",
    "- Tissus : tumeur, stroma, épiderme, vaisseaux sanguins..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3bc267",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Le dataset PUMA (Panoptic segmentation of nUclei and tissue in MelanomA) constitue la première base de données spécifique au mélanome pour la segmentation panoptique des noyaux cellulaires et des tissus :\n",
    "\n",
    "- Il comprend 155 régions d'intérêt (ROIs) de mélanomes primaires et 155 de mélanomes métastatiques, offrant ainsi un échantillonnage représentatif de la diversité morphologique de cette pathologie.\n",
    "\n",
    "- Les images sont des coupes histologiques colorées à l'hématoxyline et à l'éosine (H&E), numérisées à un grossissement de 40x avec une résolution de 1024×1024 pixels.\n",
    "\n",
    "- Chaque ROI est accompagnée d'une ROI contextuelle de 5120×5120 pixels centrée autour d'elle, permettant d'analyser l'environnement tissulaire plus large.\n",
    "\n",
    "- Les annotations des noyaux cellulaires identifient 10 types distincts : tumeur, lymphocytes, plasmocytes, histiocytes, mélanophages, neutrophiles, cellules stromales, épithélium, endothélium et cellules apoptotiques.\n",
    "\n",
    "- Les annotations tissulaires comprennent 5 catégories : tumeur, stroma, épithélium, vaisseaux sanguins et zones nécrotiques.\n",
    "\n",
    "- Toutes les annotations ont été réalisées par un professionnel médical et vérifiées par un dermato-pathologiste certifié, garantissant leur qualité et leur pertinence clinique.\n",
    "\n",
    "Ce jeu de données unique permet de développer et d'évaluer des modèles spécifiques au mélanome avec un niveau de granularité sans précédent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba678df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Prétraitement des Données\n",
    "\n",
    "1. Chargement des images TIFF et annotations GeoJSON\n",
    "2. Conversion des polygones en masques binaires\n",
    "3. Format multi-canaux : [RGB, tissue, nuclei]\n",
    "4. Découpage en patches 270×270\n",
    "5. Séparation train/test (80%/20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2203162",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notre pipeline de prétraitement transforme les données brutes PUMA en un format adapté à l'entraînement du modèle HoverNet :\n",
    "\n",
    "1. **Chargement des données sources** : Les images histologiques sont au format TIFF (1024×1024 pixels, coloration H&E). Les annotations des noyaux cellulaires et des tissus sont fournies au format GeoJSON, sous forme de polygones géoréférencés avec des attributs de classification.\n",
    "\n",
    "2. **Conversion des annotations** : Notre script `preprocess_data.py` transforme les polygones GeoJSON en masques binaires. Pour les noyaux, nous créons à la fois un masque d'instance (où chaque noyau a un identifiant unique) et un masque de type (où chaque pixel est codé selon le type cellulaire).\n",
    "\n",
    "3. **Création de tableaux multi-canaux** : Nous combinons l'image RGB avec les masques de tissu et de noyaux pour créer un tableau numpy à 5 canaux : [R, G, B, tissue_type, nuclei_type].\n",
    "\n",
    "4. **Découpage en patches** : Pour faciliter l'entraînement et augmenter le nombre d'échantillons, nous découpons chaque image en patches de 270×270 pixels.\n",
    "\n",
    "5. **Division en ensembles** : Les patches sont répartis aléatoirement entre ensemble d'entraînement (80%) et de test (20%), en veillant à maintenir une distribution équilibrée des classes.\n",
    "\n",
    "6. **Visualisation** : Pour vérifier la qualité du prétraitement, nous générons des visualisations superposant les masques de segmentation sur les images originales.\n",
    "\n",
    "Cette phase de prétraitement est essentielle pour garantir que les données sont dans un format approprié et cohérent pour l'entraînement de notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fd1a8",
   "metadata": {},
   "source": [
    "# Analyse du Script de Prétraitement\n",
    "\n",
    "Notre script `preprocess_data.py` réalise les opérations suivantes :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ca43c",
   "metadata": {},
   "source": [
    "## 1. Définition des mappings et constantes\n",
    "\n",
    "```python\n",
    "NUCLEI_MAP = {\n",
    "    \"background\": 0,\n",
    "    \"nuclei_tumor\": 1,\n",
    "    \"nuclei_stroma\": 2,\n",
    "    \"nuclei_epithelium\": 3,\n",
    "    \"nuclei_histiocyte\": 4,\n",
    "    \"nuclei_melanophage\": 5,\n",
    "    \"nuclei_neutrophil\": 6,\n",
    "    \"nuclei_lymphocyte\": 7,\n",
    "    \"nuclei_plasma_cell\": 8,\n",
    "    \"nuclei_endothelium\": 9,\n",
    "    \"nuclei_apoptosis\": 10,\n",
    "}\n",
    "\n",
    "TISSUE_MAP = {\n",
    "    \"background\": 0,\n",
    "    \"tissue_tumor\": 1,\n",
    "    \"tissue_stroma\": 2,\n",
    "    \"tissue_epithelium\": 3,\n",
    "    \"tissue_blood_vessel\": 4,\n",
    "    \"tissue_necrosis\": 5,\n",
    "    \"tissue_epidermis\": 6,\n",
    "    \"tissue_white_background\": 7,\n",
    "}\n",
    "```\n",
    "\n",
    "Nous définissons des dictionnaires qui associent chaque type cellulaire et tissulaire à une valeur numérique unique, utilisée pour coder les masques de segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25fd935",
   "metadata": {},
   "source": [
    "## 2. Validation des données GeoJSON avec Pydantic\n",
    "\n",
    "```python\n",
    "class GeometryPolygon(BaseModel):\n",
    "    type: Literal[\"Polygon\"]\n",
    "    coordinates: list[list[list[float]]]\n",
    "\n",
    "class Classification(BaseModel):\n",
    "    name: str\n",
    "    color: list[int]\n",
    "\n",
    "class GeoJSONData(BaseModel):\n",
    "    type: str = Field(\"FeatureCollection\")\n",
    "    features: List[Feature]\n",
    "```\n",
    "\n",
    "Nous utilisons Pydantic pour valider la structure des fichiers GeoJSON et faciliter l'extraction des informations nécessaires, ce qui garantit la robustesse du prétraitement face à des données potentiellement mal formatées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b015125f",
   "metadata": {},
   "source": [
    "## 3. Conversion des polygones en masques\n",
    "\n",
    "```python\n",
    "def geojson_to_mask(geojson_path, image_shape, mapping):\n",
    "    mask = np.zeros(image_shape[:2], dtype=np.int8)\n",
    "    data = load_geojson(geojson_path)\n",
    "    \n",
    "    for feature in data.features:\n",
    "        # Extraire les coordonnées du polygone\n",
    "        if feature.geometry.type == \"Polygon\":\n",
    "            polygons = [feature.geometry.coordinates[0]]\n",
    "        elif feature.geometry.type == \"MultiPolygon\":\n",
    "            polygons = [poly[0] for poly in feature.geometry.coordinates]\n",
    "        \n",
    "        for polygon_coords in polygons:\n",
    "            points = np.array(polygon_coords, dtype=np.int32)\n",
    "            type_int = mapping[feature.properties.classification.name]\n",
    "            cv2.fillPoly(mask, [points], type_int)\n",
    "    \n",
    "    return mask\n",
    "```\n",
    "\n",
    "Cette fonction centrale convertit les coordonnées des polygones GeoJSON en masques binaires. Nous utilisons OpenCV (`cv2.fillPoly`) pour remplir efficacement chaque polygone avec la valeur correspondant à son type cellulaire ou tissulaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7712d904",
   "metadata": {},
   "source": [
    "## 4. Extraction et sauvegarde des patches\n",
    "\n",
    "```python\n",
    "def extract_patches(image, patch_size):\n",
    "    height, width = image.shape[:2]\n",
    "    patches = []\n",
    "    \n",
    "    # Extract patches with a sliding window approach\n",
    "    for y in range(0, height - patch_size[0] + 1, patch_size[0]):\n",
    "        for x in range(0, width - patch_size[1] + 1, patch_size[1]):\n",
    "            if len(image.shape) == 3:  # RGB image\n",
    "                patch = image[y:y+patch_size[0], x:x+patch_size[1], :]\n",
    "            else:  # Mask (2D)\n",
    "                patch = image[y:y+patch_size[0], x:x+patch_size[1]]\n",
    "            \n",
    "            patches.append((patch, (y, x)))\n",
    "    \n",
    "    return patches\n",
    "```\n",
    "\n",
    "Nous découpons les images et les masques en patches de taille fixe (270×270 pixels) avec une approche de fenêtre glissante, en conservant les coordonnées pour maintenir la traçabilité spatiale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd35e9d",
   "metadata": {},
   "source": [
    "## 5. Traitement en parallèle\n",
    "\n",
    "```python\n",
    "# Process images in parallel with ThreadPoolExecutor\n",
    "with ThreadPoolExecutor(max_workers=args.max_threads) as executor:\n",
    "    futures = {\n",
    "        executor.submit(\n",
    "            process_image,\n",
    "            image_path,\n",
    "            args.nucleis,\n",
    "            args.tissues,\n",
    "            args.output,\n",
    "        ): image_path\n",
    "        for image_path in image_files\n",
    "    }\n",
    "```\n",
    "\n",
    "Pour optimiser le temps de traitement, nous utilisons `ThreadPoolExecutor` qui permet de traiter plusieurs images simultanément, ce qui est crucial pour les grands jeux de données comme PUMA qui contient 310 ROIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60603c75",
   "metadata": {},
   "source": [
    "## 6. Visualisation des masques générés\n",
    "\n",
    "```python\n",
    "def visualize_masks(img, tissue_mask, nuclei_mask, basename, output_dir):\n",
    "    # Create visualization directory\n",
    "    vis_dir = output_dir / \"visualizations\"\n",
    "    vis_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create a figure with three panels\n",
    "    figure, axes = plt.subplots(1, 3, figsize=(12, 4), dpi=100)\n",
    "    \n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(\"Original image\")\n",
    "    \n",
    "    plot_overlay(img, tissue_mask, axes[1], TISSUE_COLOR_MAP, TISSUE_MAP)\n",
    "    axes[1].set_title(\"Tissue overlay\")\n",
    "    \n",
    "    plot_overlay(img, nuclei_mask, axes[2], NUCLEI_COLOR_MAP, NUCLEI_MAP)\n",
    "    axes[2].set_title(\"Nuclei overlay\")\n",
    "```\n",
    "\n",
    "Cette fonction génère des visualisations qui permettent de vérifier la qualité du prétraitement en superposant les masques de segmentation (colorés selon le type cellulaire ou tissulaire) sur les images originales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae1ca68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Architecture HoverNet\n",
    "\n",
    "- Réseau de neurones convolutif avec encodeur-décodeur\n",
    "- Sorties multiples :\n",
    "  - Segmentation des instances (noyaux individuels)\n",
    "  - Classification des types cellulaires\n",
    "  - Cartes de distances horizontales et verticales (HoVer-maps)\n",
    "\n",
    "→ Permet simultanément de détecter, segmenter et classifier les noyaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a5cf1",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "HoverNet est une architecture de deep learning spécialement conçue pour la segmentation et la classification simultanées des noyaux cellulaires dans les images histopathologiques :\n",
    "\n",
    "- **Architecture de base** : HoverNet utilise un réseau de neurones à convolution avec une structure encodeur-décodeur, inspirée de U-Net. L'encodeur extrait des caractéristiques de plus en plus abstraites, tandis que le décodeur reconstitue progressivement les détails spatiaux.\n",
    "\n",
    "- **Particularité des HoVer-maps** : L'innovation majeure de HoverNet réside dans l'utilisation de cartes de distances horizontales et verticales (HoVer pour Horizontal-Vertical). Ces cartes encodent pour chaque pixel sa distance relative aux bords des noyaux dans les directions horizontale et verticale, facilitant ainsi la séparation des noyaux qui se touchent.\n",
    "\n",
    "- **Branches multiples** : L'architecture comporte trois branches parallèles en sortie du décodeur :\n",
    "  1. Une branche de segmentation binaire (noyau vs fond)\n",
    "  2. Une branche de cartes HoVer pour la séparation des instances\n",
    "  3. Une branche de classification pour prédire le type de chaque noyau\n",
    "\n",
    "- **Avantages** : Cette approche permet de résoudre simultanément trois problèmes difficiles : la détection des noyaux, leur segmentation individuelle (même lorsqu'ils sont agglutinés), et leur classification par type cellulaire.\n",
    "\n",
    "- **HoverNeXt** : Version améliorée qui intègre des techniques d'augmentation de données plus sophistiquées et des mécanismes d'inférence adaptative pour mieux gérer les variations de coloration et de morphologie entre les échantillons.\n",
    "\n",
    "Ces caractéristiques font de HoverNet une architecture particulièrement adaptée au challenge de la segmentation panoptique dans les images histopathologiques du mélanome."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
